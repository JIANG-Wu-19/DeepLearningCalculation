{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:45:42.070710900Z",
     "start_time": "2024-02-29T10:45:39.624249600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from LeNet import LeNet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:45:42.141572Z",
     "start_time": "2024-02-29T10:45:42.073704100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 7\n"
     ]
    }
   ],
   "source": [
    "# LeNet = nn.Sequential(\n",
    "#     nn.Conv2d(1, 6, kernel_size=(5, 5), padding=2),\n",
    "#     nn.ReLU(),\n",
    "#     # nn.Sigmoid(),\n",
    "#     # nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "#     nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#\n",
    "#     nn.Conv2d(6, 16, kernel_size=(5, 5)),\n",
    "#     # nn.Sigmoid(),\n",
    "#     nn.ReLU(),\n",
    "#     # nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "#     nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#\n",
    "#     nn.Flatten(),\n",
    "#\n",
    "#     nn.Linear(16 * 5 * 5, 120),\n",
    "#     # nn.Sigmoid(),\n",
    "#     nn.ReLU(),\n",
    "#\n",
    "#     nn.Linear(120, 84),\n",
    "#     # nn.Sigmoid(),\n",
    "#     nn.ReLU(),\n",
    "#\n",
    "#     nn.Linear(84, 10)\n",
    "# )\n",
    "writer=SummaryWriter(\"logs\")\n",
    "torch.cuda.empty_cache ()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mnist_training = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "mnist_test = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "img,label=mnist_test[0]\n",
    "print(img.shape,label)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:45:42.146584800Z",
     "start_time": "2024-02-29T10:45:42.144566800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "lr = 0.1\n",
    "epochs = 20\n",
    "\n",
    "train_dataloader = DataLoader(mnist_training, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T10:48:31.357194500Z",
     "start_time": "2024-02-29T10:45:42.153566200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \n",
      "---------------------\n",
      "loss:2.586294 [    0/ 60000]\n",
      "loss:2.332217 [ 2560/ 60000]\n",
      "loss:2.328431 [ 5120/ 60000]\n",
      "loss:2.346096 [ 7680/ 60000]\n",
      "loss:2.320854 [10240/ 60000]\n",
      "loss:2.303083 [12800/ 60000]\n",
      "loss:2.307433 [15360/ 60000]\n",
      "loss:2.310144 [17920/ 60000]\n",
      "loss:2.314940 [20480/ 60000]\n",
      "loss:2.311887 [23040/ 60000]\n",
      "loss:2.296582 [25600/ 60000]\n",
      "loss:2.317631 [28160/ 60000]\n",
      "loss:2.314351 [30720/ 60000]\n",
      "loss:2.313234 [33280/ 60000]\n",
      "loss:2.330926 [35840/ 60000]\n",
      "loss:2.305202 [38400/ 60000]\n",
      "loss:2.294136 [40960/ 60000]\n",
      "loss:2.298667 [43520/ 60000]\n",
      "loss:2.318080 [46080/ 60000]\n",
      "loss:2.314773 [48640/ 60000]\n",
      "loss:2.298622 [51200/ 60000]\n",
      "loss:2.303575 [53760/ 60000]\n",
      "loss:2.301598 [56320/ 60000]\n",
      "loss:2.315878 [58880/ 60000]\n",
      "test: acc 20.829999923706055\n",
      "epoch 1 \n",
      "---------------------\n",
      "loss:2.305477 [    0/ 60000]\n",
      "loss:2.317616 [ 2560/ 60000]\n",
      "loss:2.299921 [ 5120/ 60000]\n",
      "loss:2.310353 [ 7680/ 60000]\n",
      "loss:2.294155 [10240/ 60000]\n",
      "loss:2.307668 [12800/ 60000]\n",
      "loss:2.300088 [15360/ 60000]\n",
      "loss:2.302742 [17920/ 60000]\n",
      "loss:2.302960 [20480/ 60000]\n",
      "loss:2.304171 [23040/ 60000]\n",
      "loss:2.300260 [25600/ 60000]\n",
      "loss:2.292938 [28160/ 60000]\n",
      "loss:2.304187 [30720/ 60000]\n",
      "loss:2.312029 [33280/ 60000]\n",
      "loss:2.298709 [35840/ 60000]\n",
      "loss:2.291720 [38400/ 60000]\n",
      "loss:2.306342 [40960/ 60000]\n",
      "loss:2.297398 [43520/ 60000]\n",
      "loss:2.311276 [46080/ 60000]\n",
      "loss:2.305887 [48640/ 60000]\n",
      "loss:2.299309 [51200/ 60000]\n",
      "loss:2.303328 [53760/ 60000]\n",
      "loss:2.305229 [56320/ 60000]\n",
      "loss:2.294670 [58880/ 60000]\n",
      "test: acc 11.34999942779541\n",
      "epoch 2 \n",
      "---------------------\n",
      "loss:2.293601 [    0/ 60000]\n",
      "loss:2.292675 [ 2560/ 60000]\n",
      "loss:2.292356 [ 5120/ 60000]\n",
      "loss:2.297703 [ 7680/ 60000]\n",
      "loss:2.284855 [10240/ 60000]\n",
      "loss:2.286905 [12800/ 60000]\n",
      "loss:2.278963 [15360/ 60000]\n",
      "loss:2.280165 [17920/ 60000]\n",
      "loss:2.270878 [20480/ 60000]\n",
      "loss:2.237217 [23040/ 60000]\n",
      "loss:2.165820 [25600/ 60000]\n",
      "loss:2.115193 [28160/ 60000]\n",
      "loss:1.992823 [30720/ 60000]\n",
      "loss:1.896447 [33280/ 60000]\n",
      "loss:1.834234 [35840/ 60000]\n",
      "loss:1.705143 [38400/ 60000]\n",
      "loss:1.534505 [40960/ 60000]\n",
      "loss:1.384961 [43520/ 60000]\n",
      "loss:1.167177 [46080/ 60000]\n",
      "loss:1.120961 [48640/ 60000]\n",
      "loss:0.851135 [51200/ 60000]\n",
      "loss:0.780837 [53760/ 60000]\n",
      "loss:0.742315 [56320/ 60000]\n",
      "loss:0.794330 [58880/ 60000]\n",
      "test: acc 79.47000122070312\n",
      "epoch 3 \n",
      "---------------------\n",
      "loss:0.612792 [    0/ 60000]\n",
      "loss:0.627473 [ 2560/ 60000]\n",
      "loss:0.578896 [ 5120/ 60000]\n",
      "loss:0.664936 [ 7680/ 60000]\n",
      "loss:0.521616 [10240/ 60000]\n",
      "loss:0.489661 [12800/ 60000]\n",
      "loss:0.554282 [15360/ 60000]\n",
      "loss:0.517592 [17920/ 60000]\n",
      "loss:0.513694 [20480/ 60000]\n",
      "loss:0.432268 [23040/ 60000]\n",
      "loss:0.560776 [25600/ 60000]\n",
      "loss:0.454466 [28160/ 60000]\n",
      "loss:0.462272 [30720/ 60000]\n",
      "loss:0.358180 [33280/ 60000]\n",
      "loss:0.306939 [35840/ 60000]\n",
      "loss:0.434714 [38400/ 60000]\n",
      "loss:0.420328 [40960/ 60000]\n",
      "loss:0.268431 [43520/ 60000]\n",
      "loss:0.409098 [46080/ 60000]\n",
      "loss:0.360070 [48640/ 60000]\n",
      "loss:0.326568 [51200/ 60000]\n",
      "loss:0.316331 [53760/ 60000]\n",
      "loss:0.275647 [56320/ 60000]\n",
      "loss:0.297399 [58880/ 60000]\n",
      "test: acc 90.1500015258789\n",
      "epoch 4 \n",
      "---------------------\n",
      "loss:0.414984 [    0/ 60000]\n",
      "loss:0.353728 [ 2560/ 60000]\n",
      "loss:0.330676 [ 5120/ 60000]\n",
      "loss:0.272317 [ 7680/ 60000]\n",
      "loss:0.301689 [10240/ 60000]\n",
      "loss:0.244968 [12800/ 60000]\n",
      "loss:0.332631 [15360/ 60000]\n",
      "loss:0.295612 [17920/ 60000]\n",
      "loss:0.317353 [20480/ 60000]\n",
      "loss:0.308023 [23040/ 60000]\n",
      "loss:0.259838 [25600/ 60000]\n",
      "loss:0.281710 [28160/ 60000]\n",
      "loss:0.247692 [30720/ 60000]\n",
      "loss:0.240373 [33280/ 60000]\n",
      "loss:0.246309 [35840/ 60000]\n",
      "loss:0.211714 [38400/ 60000]\n",
      "loss:0.271432 [40960/ 60000]\n",
      "loss:0.202259 [43520/ 60000]\n",
      "loss:0.155195 [46080/ 60000]\n",
      "loss:0.183008 [48640/ 60000]\n",
      "loss:0.215246 [51200/ 60000]\n",
      "loss:0.195953 [53760/ 60000]\n",
      "loss:0.226778 [56320/ 60000]\n",
      "loss:0.288219 [58880/ 60000]\n",
      "test: acc 93.52999877929688\n",
      "epoch 5 \n",
      "---------------------\n",
      "loss:0.322724 [    0/ 60000]\n",
      "loss:0.219002 [ 2560/ 60000]\n",
      "loss:0.203198 [ 5120/ 60000]\n",
      "loss:0.194040 [ 7680/ 60000]\n",
      "loss:0.220277 [10240/ 60000]\n",
      "loss:0.154204 [12800/ 60000]\n",
      "loss:0.183734 [15360/ 60000]\n",
      "loss:0.263052 [17920/ 60000]\n",
      "loss:0.218268 [20480/ 60000]\n",
      "loss:0.175479 [23040/ 60000]\n",
      "loss:0.232032 [25600/ 60000]\n",
      "loss:0.186976 [28160/ 60000]\n",
      "loss:0.189773 [30720/ 60000]\n",
      "loss:0.197203 [33280/ 60000]\n",
      "loss:0.179865 [35840/ 60000]\n",
      "loss:0.168521 [38400/ 60000]\n",
      "loss:0.152836 [40960/ 60000]\n",
      "loss:0.175761 [43520/ 60000]\n",
      "loss:0.174704 [46080/ 60000]\n",
      "loss:0.267114 [48640/ 60000]\n",
      "loss:0.153831 [51200/ 60000]\n",
      "loss:0.143070 [53760/ 60000]\n",
      "loss:0.222714 [56320/ 60000]\n",
      "loss:0.192513 [58880/ 60000]\n",
      "test: acc 95.08999633789062\n",
      "epoch 6 \n",
      "---------------------\n",
      "loss:0.132630 [    0/ 60000]\n",
      "loss:0.117425 [ 2560/ 60000]\n",
      "loss:0.228143 [ 5120/ 60000]\n",
      "loss:0.121999 [ 7680/ 60000]\n",
      "loss:0.187554 [10240/ 60000]\n",
      "loss:0.125879 [12800/ 60000]\n",
      "loss:0.135407 [15360/ 60000]\n",
      "loss:0.217263 [17920/ 60000]\n",
      "loss:0.144485 [20480/ 60000]\n",
      "loss:0.104665 [23040/ 60000]\n",
      "loss:0.109042 [25600/ 60000]\n",
      "loss:0.126895 [28160/ 60000]\n",
      "loss:0.136991 [30720/ 60000]\n",
      "loss:0.133628 [33280/ 60000]\n",
      "loss:0.165680 [35840/ 60000]\n",
      "loss:0.129421 [38400/ 60000]\n",
      "loss:0.180137 [40960/ 60000]\n",
      "loss:0.196520 [43520/ 60000]\n",
      "loss:0.126008 [46080/ 60000]\n",
      "loss:0.141954 [48640/ 60000]\n",
      "loss:0.129232 [51200/ 60000]\n",
      "loss:0.175205 [53760/ 60000]\n",
      "loss:0.114398 [56320/ 60000]\n",
      "loss:0.162208 [58880/ 60000]\n",
      "test: acc 96.19999694824219\n",
      "epoch 7 \n",
      "---------------------\n",
      "loss:0.180881 [    0/ 60000]\n",
      "loss:0.122514 [ 2560/ 60000]\n",
      "loss:0.079977 [ 5120/ 60000]\n",
      "loss:0.086646 [ 7680/ 60000]\n",
      "loss:0.132928 [10240/ 60000]\n",
      "loss:0.182860 [12800/ 60000]\n",
      "loss:0.170141 [15360/ 60000]\n",
      "loss:0.215847 [17920/ 60000]\n",
      "loss:0.160491 [20480/ 60000]\n",
      "loss:0.144942 [23040/ 60000]\n",
      "loss:0.098945 [25600/ 60000]\n",
      "loss:0.171744 [28160/ 60000]\n",
      "loss:0.093772 [30720/ 60000]\n",
      "loss:0.130261 [33280/ 60000]\n",
      "loss:0.124966 [35840/ 60000]\n",
      "loss:0.132421 [38400/ 60000]\n",
      "loss:0.119696 [40960/ 60000]\n",
      "loss:0.111138 [43520/ 60000]\n",
      "loss:0.130305 [46080/ 60000]\n",
      "loss:0.200814 [48640/ 60000]\n",
      "loss:0.086997 [51200/ 60000]\n",
      "loss:0.074998 [53760/ 60000]\n",
      "loss:0.106642 [56320/ 60000]\n",
      "loss:0.144651 [58880/ 60000]\n",
      "test: acc 96.61000061035156\n",
      "epoch 8 \n",
      "---------------------\n",
      "loss:0.110530 [    0/ 60000]\n",
      "loss:0.105150 [ 2560/ 60000]\n",
      "loss:0.129557 [ 5120/ 60000]\n",
      "loss:0.126051 [ 7680/ 60000]\n",
      "loss:0.104930 [10240/ 60000]\n",
      "loss:0.109530 [12800/ 60000]\n",
      "loss:0.067853 [15360/ 60000]\n",
      "loss:0.158837 [17920/ 60000]\n",
      "loss:0.099355 [20480/ 60000]\n",
      "loss:0.146268 [23040/ 60000]\n",
      "loss:0.111640 [25600/ 60000]\n",
      "loss:0.076266 [28160/ 60000]\n",
      "loss:0.087452 [30720/ 60000]\n",
      "loss:0.106571 [33280/ 60000]\n",
      "loss:0.137764 [35840/ 60000]\n",
      "loss:0.125206 [38400/ 60000]\n",
      "loss:0.113659 [40960/ 60000]\n",
      "loss:0.096831 [43520/ 60000]\n",
      "loss:0.103528 [46080/ 60000]\n",
      "loss:0.093871 [48640/ 60000]\n",
      "loss:0.060931 [51200/ 60000]\n",
      "loss:0.128692 [53760/ 60000]\n",
      "loss:0.118477 [56320/ 60000]\n",
      "loss:0.095041 [58880/ 60000]\n",
      "test: acc 97.1199951171875\n",
      "epoch 9 \n",
      "---------------------\n",
      "loss:0.058203 [    0/ 60000]\n",
      "loss:0.099656 [ 2560/ 60000]\n",
      "loss:0.082188 [ 5120/ 60000]\n",
      "loss:0.098890 [ 7680/ 60000]\n",
      "loss:0.092327 [10240/ 60000]\n",
      "loss:0.065500 [12800/ 60000]\n",
      "loss:0.123263 [15360/ 60000]\n",
      "loss:0.086439 [17920/ 60000]\n",
      "loss:0.070007 [20480/ 60000]\n",
      "loss:0.031441 [23040/ 60000]\n",
      "loss:0.082011 [25600/ 60000]\n",
      "loss:0.114266 [28160/ 60000]\n",
      "loss:0.084519 [30720/ 60000]\n",
      "loss:0.079940 [33280/ 60000]\n",
      "loss:0.067399 [35840/ 60000]\n",
      "loss:0.155854 [38400/ 60000]\n",
      "loss:0.068196 [40960/ 60000]\n",
      "loss:0.079912 [43520/ 60000]\n",
      "loss:0.100336 [46080/ 60000]\n",
      "loss:0.113385 [48640/ 60000]\n",
      "loss:0.059070 [51200/ 60000]\n",
      "loss:0.087837 [53760/ 60000]\n",
      "loss:0.070485 [56320/ 60000]\n",
      "loss:0.140992 [58880/ 60000]\n",
      "test: acc 97.48999786376953\n",
      "epoch 10 \n",
      "---------------------\n",
      "loss:0.054458 [    0/ 60000]\n",
      "loss:0.118145 [ 2560/ 60000]\n",
      "loss:0.081938 [ 5120/ 60000]\n",
      "loss:0.136014 [ 7680/ 60000]\n",
      "loss:0.054131 [10240/ 60000]\n",
      "loss:0.095267 [12800/ 60000]\n",
      "loss:0.082333 [15360/ 60000]\n",
      "loss:0.104730 [17920/ 60000]\n",
      "loss:0.102490 [20480/ 60000]\n",
      "loss:0.073600 [23040/ 60000]\n",
      "loss:0.108884 [25600/ 60000]\n",
      "loss:0.104270 [28160/ 60000]\n",
      "loss:0.124765 [30720/ 60000]\n",
      "loss:0.112002 [33280/ 60000]\n",
      "loss:0.052447 [35840/ 60000]\n",
      "loss:0.100704 [38400/ 60000]\n",
      "loss:0.081086 [40960/ 60000]\n",
      "loss:0.093704 [43520/ 60000]\n",
      "loss:0.080373 [46080/ 60000]\n",
      "loss:0.051519 [48640/ 60000]\n",
      "loss:0.091024 [51200/ 60000]\n",
      "loss:0.080311 [53760/ 60000]\n",
      "loss:0.081443 [56320/ 60000]\n",
      "loss:0.073113 [58880/ 60000]\n",
      "test: acc 97.48999786376953\n",
      "epoch 11 \n",
      "---------------------\n",
      "loss:0.089480 [    0/ 60000]\n",
      "loss:0.090615 [ 2560/ 60000]\n",
      "loss:0.051164 [ 5120/ 60000]\n",
      "loss:0.095634 [ 7680/ 60000]\n",
      "loss:0.115754 [10240/ 60000]\n",
      "loss:0.090021 [12800/ 60000]\n",
      "loss:0.064726 [15360/ 60000]\n",
      "loss:0.109342 [17920/ 60000]\n",
      "loss:0.121069 [20480/ 60000]\n",
      "loss:0.053129 [23040/ 60000]\n",
      "loss:0.061153 [25600/ 60000]\n",
      "loss:0.082578 [28160/ 60000]\n",
      "loss:0.044948 [30720/ 60000]\n",
      "loss:0.081825 [33280/ 60000]\n",
      "loss:0.086391 [35840/ 60000]\n",
      "loss:0.080773 [38400/ 60000]\n",
      "loss:0.117970 [40960/ 60000]\n",
      "loss:0.064766 [43520/ 60000]\n",
      "loss:0.093724 [46080/ 60000]\n",
      "loss:0.054017 [48640/ 60000]\n",
      "loss:0.080695 [51200/ 60000]\n",
      "loss:0.070954 [53760/ 60000]\n",
      "loss:0.090394 [56320/ 60000]\n",
      "loss:0.079944 [58880/ 60000]\n",
      "test: acc 97.7699966430664\n",
      "epoch 12 \n",
      "---------------------\n",
      "loss:0.049132 [    0/ 60000]\n",
      "loss:0.090850 [ 2560/ 60000]\n",
      "loss:0.093802 [ 5120/ 60000]\n",
      "loss:0.079279 [ 7680/ 60000]\n",
      "loss:0.059684 [10240/ 60000]\n",
      "loss:0.090292 [12800/ 60000]\n",
      "loss:0.069538 [15360/ 60000]\n",
      "loss:0.048453 [17920/ 60000]\n",
      "loss:0.090965 [20480/ 60000]\n",
      "loss:0.088022 [23040/ 60000]\n",
      "loss:0.077407 [25600/ 60000]\n",
      "loss:0.036095 [28160/ 60000]\n",
      "loss:0.109809 [30720/ 60000]\n",
      "loss:0.092841 [33280/ 60000]\n",
      "loss:0.071917 [35840/ 60000]\n",
      "loss:0.069917 [38400/ 60000]\n",
      "loss:0.106983 [40960/ 60000]\n",
      "loss:0.137435 [43520/ 60000]\n",
      "loss:0.084511 [46080/ 60000]\n",
      "loss:0.066972 [48640/ 60000]\n",
      "loss:0.077081 [51200/ 60000]\n",
      "loss:0.075222 [53760/ 60000]\n",
      "loss:0.068527 [56320/ 60000]\n",
      "loss:0.085739 [58880/ 60000]\n",
      "test: acc 97.90999603271484\n",
      "epoch 13 \n",
      "---------------------\n",
      "loss:0.093478 [    0/ 60000]\n",
      "loss:0.103370 [ 2560/ 60000]\n",
      "loss:0.096283 [ 5120/ 60000]\n",
      "loss:0.042385 [ 7680/ 60000]\n",
      "loss:0.083386 [10240/ 60000]\n",
      "loss:0.070761 [12800/ 60000]\n",
      "loss:0.049561 [15360/ 60000]\n",
      "loss:0.046382 [17920/ 60000]\n",
      "loss:0.058566 [20480/ 60000]\n",
      "loss:0.061682 [23040/ 60000]\n",
      "loss:0.050248 [25600/ 60000]\n",
      "loss:0.133241 [28160/ 60000]\n",
      "loss:0.012537 [30720/ 60000]\n",
      "loss:0.075899 [33280/ 60000]\n",
      "loss:0.087281 [35840/ 60000]\n",
      "loss:0.044810 [38400/ 60000]\n",
      "loss:0.060916 [40960/ 60000]\n",
      "loss:0.078865 [43520/ 60000]\n",
      "loss:0.094230 [46080/ 60000]\n",
      "loss:0.116671 [48640/ 60000]\n",
      "loss:0.031495 [51200/ 60000]\n",
      "loss:0.086078 [53760/ 60000]\n",
      "loss:0.038561 [56320/ 60000]\n",
      "loss:0.081355 [58880/ 60000]\n",
      "test: acc 97.87999725341797\n",
      "epoch 14 \n",
      "---------------------\n",
      "loss:0.047532 [    0/ 60000]\n",
      "loss:0.057705 [ 2560/ 60000]\n",
      "loss:0.047292 [ 5120/ 60000]\n",
      "loss:0.056688 [ 7680/ 60000]\n",
      "loss:0.038850 [10240/ 60000]\n",
      "loss:0.072568 [12800/ 60000]\n",
      "loss:0.036091 [15360/ 60000]\n",
      "loss:0.069503 [17920/ 60000]\n",
      "loss:0.045656 [20480/ 60000]\n",
      "loss:0.044645 [23040/ 60000]\n",
      "loss:0.089375 [25600/ 60000]\n",
      "loss:0.057112 [28160/ 60000]\n",
      "loss:0.071415 [30720/ 60000]\n",
      "loss:0.040878 [33280/ 60000]\n",
      "loss:0.055943 [35840/ 60000]\n",
      "loss:0.065793 [38400/ 60000]\n",
      "loss:0.122153 [40960/ 60000]\n",
      "loss:0.038142 [43520/ 60000]\n",
      "loss:0.035724 [46080/ 60000]\n",
      "loss:0.076655 [48640/ 60000]\n",
      "loss:0.076207 [51200/ 60000]\n",
      "loss:0.046681 [53760/ 60000]\n",
      "loss:0.066673 [56320/ 60000]\n",
      "loss:0.072928 [58880/ 60000]\n",
      "test: acc 97.72000122070312\n",
      "epoch 15 \n",
      "---------------------\n",
      "loss:0.073191 [    0/ 60000]\n",
      "loss:0.051662 [ 2560/ 60000]\n",
      "loss:0.042351 [ 5120/ 60000]\n",
      "loss:0.043465 [ 7680/ 60000]\n",
      "loss:0.084452 [10240/ 60000]\n",
      "loss:0.094197 [12800/ 60000]\n",
      "loss:0.074877 [15360/ 60000]\n",
      "loss:0.041949 [17920/ 60000]\n",
      "loss:0.084632 [20480/ 60000]\n",
      "loss:0.052122 [23040/ 60000]\n",
      "loss:0.131777 [25600/ 60000]\n",
      "loss:0.042678 [28160/ 60000]\n",
      "loss:0.093170 [30720/ 60000]\n",
      "loss:0.049955 [33280/ 60000]\n",
      "loss:0.055213 [35840/ 60000]\n",
      "loss:0.061024 [38400/ 60000]\n",
      "loss:0.022739 [40960/ 60000]\n",
      "loss:0.026378 [43520/ 60000]\n",
      "loss:0.027317 [46080/ 60000]\n",
      "loss:0.060504 [48640/ 60000]\n",
      "loss:0.037307 [51200/ 60000]\n",
      "loss:0.066451 [53760/ 60000]\n",
      "loss:0.070772 [56320/ 60000]\n",
      "loss:0.075480 [58880/ 60000]\n",
      "test: acc 98.32999420166016\n",
      "epoch 16 \n",
      "---------------------\n",
      "loss:0.046879 [    0/ 60000]\n",
      "loss:0.117205 [ 2560/ 60000]\n",
      "loss:0.050078 [ 5120/ 60000]\n",
      "loss:0.079209 [ 7680/ 60000]\n",
      "loss:0.039865 [10240/ 60000]\n",
      "loss:0.102020 [12800/ 60000]\n",
      "loss:0.054241 [15360/ 60000]\n",
      "loss:0.093265 [17920/ 60000]\n",
      "loss:0.049074 [20480/ 60000]\n",
      "loss:0.022916 [23040/ 60000]\n",
      "loss:0.037299 [25600/ 60000]\n",
      "loss:0.048368 [28160/ 60000]\n",
      "loss:0.047917 [30720/ 60000]\n",
      "loss:0.060523 [33280/ 60000]\n",
      "loss:0.029869 [35840/ 60000]\n",
      "loss:0.047936 [38400/ 60000]\n",
      "loss:0.106813 [40960/ 60000]\n",
      "loss:0.070404 [43520/ 60000]\n",
      "loss:0.067545 [46080/ 60000]\n",
      "loss:0.054785 [48640/ 60000]\n",
      "loss:0.037983 [51200/ 60000]\n",
      "loss:0.066611 [53760/ 60000]\n",
      "loss:0.049168 [56320/ 60000]\n",
      "loss:0.071712 [58880/ 60000]\n",
      "test: acc 98.22000122070312\n",
      "epoch 17 \n",
      "---------------------\n",
      "loss:0.053501 [    0/ 60000]\n",
      "loss:0.073323 [ 2560/ 60000]\n",
      "loss:0.066056 [ 5120/ 60000]\n",
      "loss:0.020206 [ 7680/ 60000]\n",
      "loss:0.070753 [10240/ 60000]\n",
      "loss:0.031101 [12800/ 60000]\n",
      "loss:0.039110 [15360/ 60000]\n",
      "loss:0.094567 [17920/ 60000]\n",
      "loss:0.062536 [20480/ 60000]\n",
      "loss:0.018554 [23040/ 60000]\n",
      "loss:0.039613 [25600/ 60000]\n",
      "loss:0.089271 [28160/ 60000]\n",
      "loss:0.052854 [30720/ 60000]\n",
      "loss:0.096944 [33280/ 60000]\n",
      "loss:0.087289 [35840/ 60000]\n",
      "loss:0.083708 [38400/ 60000]\n",
      "loss:0.042675 [40960/ 60000]\n",
      "loss:0.076500 [43520/ 60000]\n",
      "loss:0.032988 [46080/ 60000]\n",
      "loss:0.032122 [48640/ 60000]\n",
      "loss:0.037179 [51200/ 60000]\n",
      "loss:0.034181 [53760/ 60000]\n",
      "loss:0.070477 [56320/ 60000]\n",
      "loss:0.046976 [58880/ 60000]\n",
      "test: acc 98.29999542236328\n",
      "epoch 18 \n",
      "---------------------\n",
      "loss:0.067362 [    0/ 60000]\n",
      "loss:0.049832 [ 2560/ 60000]\n",
      "loss:0.038093 [ 5120/ 60000]\n",
      "loss:0.034263 [ 7680/ 60000]\n",
      "loss:0.056539 [10240/ 60000]\n",
      "loss:0.067437 [12800/ 60000]\n",
      "loss:0.030906 [15360/ 60000]\n",
      "loss:0.107916 [17920/ 60000]\n",
      "loss:0.036437 [20480/ 60000]\n",
      "loss:0.077460 [23040/ 60000]\n",
      "loss:0.039964 [25600/ 60000]\n",
      "loss:0.063029 [28160/ 60000]\n",
      "loss:0.059892 [30720/ 60000]\n",
      "loss:0.018318 [33280/ 60000]\n",
      "loss:0.083130 [35840/ 60000]\n",
      "loss:0.098220 [38400/ 60000]\n",
      "loss:0.034694 [40960/ 60000]\n",
      "loss:0.036241 [43520/ 60000]\n",
      "loss:0.107814 [46080/ 60000]\n",
      "loss:0.083486 [48640/ 60000]\n",
      "loss:0.121231 [51200/ 60000]\n",
      "loss:0.031263 [53760/ 60000]\n",
      "loss:0.082253 [56320/ 60000]\n",
      "loss:0.018917 [58880/ 60000]\n",
      "test: acc 98.12999725341797\n",
      "epoch 19 \n",
      "---------------------\n",
      "loss:0.040204 [    0/ 60000]\n",
      "loss:0.029163 [ 2560/ 60000]\n",
      "loss:0.033809 [ 5120/ 60000]\n",
      "loss:0.049166 [ 7680/ 60000]\n",
      "loss:0.025451 [10240/ 60000]\n",
      "loss:0.048596 [12800/ 60000]\n",
      "loss:0.039861 [15360/ 60000]\n",
      "loss:0.015849 [17920/ 60000]\n",
      "loss:0.045008 [20480/ 60000]\n",
      "loss:0.044752 [23040/ 60000]\n",
      "loss:0.037465 [25600/ 60000]\n",
      "loss:0.042473 [28160/ 60000]\n",
      "loss:0.052996 [30720/ 60000]\n",
      "loss:0.027257 [33280/ 60000]\n",
      "loss:0.094647 [35840/ 60000]\n",
      "loss:0.024381 [38400/ 60000]\n",
      "loss:0.033184 [40960/ 60000]\n",
      "loss:0.066196 [43520/ 60000]\n",
      "loss:0.062127 [46080/ 60000]\n",
      "loss:0.029308 [48640/ 60000]\n",
      "loss:0.053817 [51200/ 60000]\n",
      "loss:0.039518 [53760/ 60000]\n",
      "loss:0.058689 [56320/ 60000]\n",
      "loss:0.048296 [58880/ 60000]\n",
      "test: acc 98.3699951171875\n"
     ]
    }
   ],
   "source": [
    "net = LeNet1().to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "net.apply(init_weights)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\n",
    "        f\"epoch {epoch} \\n---------------------\"\n",
    "    )\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(inputs)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d}/ 60000]\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        for (image, label) in test_dataloader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            output = net(image)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            acc += (pred == label).sum()\n",
    "\n",
    "        print(f\"test: acc {100 * acc / total}\")\n",
    "        \n",
    "        writer.add_scalar(\"acc\",acc/total,epoch)\n",
    "        \n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
