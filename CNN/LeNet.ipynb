{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-29T10:45:42.070710900Z",
     "start_time": "2024-02-29T10:45:39.624249600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from LeNet import LeNet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# LeNet = nn.Sequential(\n",
    "#     nn.Conv2d(1, 6, kernel_size=(5, 5), padding=2),\n",
    "#     nn.ReLU(),\n",
    "#     # nn.Sigmoid(),\n",
    "#     # nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "#     nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#\n",
    "#     nn.Conv2d(6, 16, kernel_size=(5, 5)),\n",
    "#     # nn.Sigmoid(),\n",
    "#     nn.ReLU(),\n",
    "#     # nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "#     nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#\n",
    "#     nn.Flatten(),\n",
    "#\n",
    "#     nn.Linear(16 * 5 * 5, 120),\n",
    "#     # nn.Sigmoid(),\n",
    "#     nn.ReLU(),\n",
    "#\n",
    "#     nn.Linear(120, 84),\n",
    "#     # nn.Sigmoid(),\n",
    "#     nn.ReLU(),\n",
    "#\n",
    "#     nn.Linear(84, 10)\n",
    "# )\n",
    "\n",
    "torch.cuda.empty_cache ()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mnist_training = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "mnist_test = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T10:45:42.141572Z",
     "start_time": "2024-02-29T10:45:42.073704100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "lr = 0.1\n",
    "epochs = 20\n",
    "\n",
    "train_dataloader = DataLoader(mnist_training, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T10:45:42.146584800Z",
     "start_time": "2024-02-29T10:45:42.144566800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \n",
      "---------------------\n",
      "loss:2.476747 [    0/ 60000]\n",
      "loss:2.314657 [ 2560/ 60000]\n",
      "loss:2.320744 [ 5120/ 60000]\n",
      "loss:2.313297 [ 7680/ 60000]\n",
      "loss:2.345857 [10240/ 60000]\n",
      "loss:2.306741 [12800/ 60000]\n",
      "loss:2.310573 [15360/ 60000]\n",
      "loss:2.306398 [17920/ 60000]\n",
      "loss:2.306983 [20480/ 60000]\n",
      "loss:2.312163 [23040/ 60000]\n",
      "loss:2.307168 [25600/ 60000]\n",
      "loss:2.314711 [28160/ 60000]\n",
      "loss:2.309708 [30720/ 60000]\n",
      "loss:2.312534 [33280/ 60000]\n",
      "loss:2.287562 [35840/ 60000]\n",
      "loss:2.309408 [38400/ 60000]\n",
      "loss:2.315734 [40960/ 60000]\n",
      "loss:2.318273 [43520/ 60000]\n",
      "loss:2.309153 [46080/ 60000]\n",
      "loss:2.309522 [48640/ 60000]\n",
      "loss:2.286702 [51200/ 60000]\n",
      "loss:2.305158 [53760/ 60000]\n",
      "loss:2.304250 [56320/ 60000]\n",
      "loss:2.299708 [58880/ 60000]\n",
      "test: acc 9.800000190734863\n",
      "epoch 1 \n",
      "---------------------\n",
      "loss:2.295205 [    0/ 60000]\n",
      "loss:2.296635 [ 2560/ 60000]\n",
      "loss:2.290797 [ 5120/ 60000]\n",
      "loss:2.310348 [ 7680/ 60000]\n",
      "loss:2.292323 [10240/ 60000]\n",
      "loss:2.291037 [12800/ 60000]\n",
      "loss:2.293490 [15360/ 60000]\n",
      "loss:2.296737 [17920/ 60000]\n",
      "loss:2.296382 [20480/ 60000]\n",
      "loss:2.301902 [23040/ 60000]\n",
      "loss:2.274613 [25600/ 60000]\n",
      "loss:2.251710 [28160/ 60000]\n",
      "loss:2.245766 [30720/ 60000]\n",
      "loss:2.202055 [33280/ 60000]\n",
      "loss:2.142725 [35840/ 60000]\n",
      "loss:2.028807 [38400/ 60000]\n",
      "loss:1.839417 [40960/ 60000]\n",
      "loss:1.724911 [43520/ 60000]\n",
      "loss:1.613597 [46080/ 60000]\n",
      "loss:1.480296 [48640/ 60000]\n",
      "loss:1.311637 [51200/ 60000]\n",
      "loss:1.207075 [53760/ 60000]\n",
      "loss:1.022801 [56320/ 60000]\n",
      "loss:0.847591 [58880/ 60000]\n",
      "test: acc 71.04000091552734\n",
      "epoch 2 \n",
      "---------------------\n",
      "loss:0.893695 [    0/ 60000]\n",
      "loss:0.840820 [ 2560/ 60000]\n",
      "loss:0.698415 [ 5120/ 60000]\n",
      "loss:0.716864 [ 7680/ 60000]\n",
      "loss:0.616068 [10240/ 60000]\n",
      "loss:0.580233 [12800/ 60000]\n",
      "loss:0.680056 [15360/ 60000]\n",
      "loss:0.558386 [17920/ 60000]\n",
      "loss:0.673704 [20480/ 60000]\n",
      "loss:0.499782 [23040/ 60000]\n",
      "loss:0.358478 [25600/ 60000]\n",
      "loss:0.407039 [28160/ 60000]\n",
      "loss:0.489808 [30720/ 60000]\n",
      "loss:0.402380 [33280/ 60000]\n",
      "loss:0.384401 [35840/ 60000]\n",
      "loss:0.318912 [38400/ 60000]\n",
      "loss:0.542051 [40960/ 60000]\n",
      "loss:0.416528 [43520/ 60000]\n",
      "loss:0.294016 [46080/ 60000]\n",
      "loss:0.383079 [48640/ 60000]\n",
      "loss:0.318021 [51200/ 60000]\n",
      "loss:0.322834 [53760/ 60000]\n",
      "loss:0.329002 [56320/ 60000]\n",
      "loss:0.398352 [58880/ 60000]\n",
      "test: acc 89.98999786376953\n",
      "epoch 3 \n",
      "---------------------\n",
      "loss:0.314731 [    0/ 60000]\n",
      "loss:0.328785 [ 2560/ 60000]\n",
      "loss:0.286843 [ 5120/ 60000]\n",
      "loss:0.370967 [ 7680/ 60000]\n",
      "loss:0.316861 [10240/ 60000]\n",
      "loss:0.282424 [12800/ 60000]\n",
      "loss:0.401597 [15360/ 60000]\n",
      "loss:0.335867 [17920/ 60000]\n",
      "loss:0.263353 [20480/ 60000]\n",
      "loss:0.233677 [23040/ 60000]\n",
      "loss:0.271146 [25600/ 60000]\n",
      "loss:0.298281 [28160/ 60000]\n",
      "loss:0.274831 [30720/ 60000]\n",
      "loss:0.249502 [33280/ 60000]\n",
      "loss:0.186751 [35840/ 60000]\n",
      "loss:0.224721 [38400/ 60000]\n",
      "loss:0.258989 [40960/ 60000]\n",
      "loss:0.264845 [43520/ 60000]\n",
      "loss:0.244783 [46080/ 60000]\n",
      "loss:0.276923 [48640/ 60000]\n",
      "loss:0.220061 [51200/ 60000]\n",
      "loss:0.156544 [53760/ 60000]\n",
      "loss:0.263788 [56320/ 60000]\n",
      "loss:0.176570 [58880/ 60000]\n",
      "test: acc 93.47000122070312\n",
      "epoch 4 \n",
      "---------------------\n",
      "loss:0.271057 [    0/ 60000]\n",
      "loss:0.275624 [ 2560/ 60000]\n",
      "loss:0.221364 [ 5120/ 60000]\n",
      "loss:0.206500 [ 7680/ 60000]\n",
      "loss:0.245397 [10240/ 60000]\n",
      "loss:0.198900 [12800/ 60000]\n",
      "loss:0.184785 [15360/ 60000]\n",
      "loss:0.150067 [17920/ 60000]\n",
      "loss:0.232075 [20480/ 60000]\n",
      "loss:0.164495 [23040/ 60000]\n",
      "loss:0.198453 [25600/ 60000]\n",
      "loss:0.242287 [28160/ 60000]\n",
      "loss:0.239364 [30720/ 60000]\n",
      "loss:0.229029 [33280/ 60000]\n",
      "loss:0.253496 [35840/ 60000]\n",
      "loss:0.231323 [38400/ 60000]\n",
      "loss:0.163951 [40960/ 60000]\n",
      "loss:0.151084 [43520/ 60000]\n",
      "loss:0.136757 [46080/ 60000]\n",
      "loss:0.127041 [48640/ 60000]\n",
      "loss:0.184272 [51200/ 60000]\n",
      "loss:0.118381 [53760/ 60000]\n",
      "loss:0.174663 [56320/ 60000]\n",
      "loss:0.198534 [58880/ 60000]\n",
      "test: acc 95.12999725341797\n",
      "epoch 5 \n",
      "---------------------\n",
      "loss:0.174734 [    0/ 60000]\n",
      "loss:0.159540 [ 2560/ 60000]\n",
      "loss:0.132671 [ 5120/ 60000]\n",
      "loss:0.155270 [ 7680/ 60000]\n",
      "loss:0.217610 [10240/ 60000]\n",
      "loss:0.099539 [12800/ 60000]\n",
      "loss:0.119164 [15360/ 60000]\n",
      "loss:0.230247 [17920/ 60000]\n",
      "loss:0.159162 [20480/ 60000]\n",
      "loss:0.102840 [23040/ 60000]\n",
      "loss:0.158801 [25600/ 60000]\n",
      "loss:0.156886 [28160/ 60000]\n",
      "loss:0.120006 [30720/ 60000]\n",
      "loss:0.123822 [33280/ 60000]\n",
      "loss:0.170125 [35840/ 60000]\n",
      "loss:0.139290 [38400/ 60000]\n",
      "loss:0.134646 [40960/ 60000]\n",
      "loss:0.094825 [43520/ 60000]\n",
      "loss:0.186692 [46080/ 60000]\n",
      "loss:0.154382 [48640/ 60000]\n",
      "loss:0.173148 [51200/ 60000]\n",
      "loss:0.137087 [53760/ 60000]\n",
      "loss:0.072495 [56320/ 60000]\n",
      "loss:0.180786 [58880/ 60000]\n",
      "test: acc 95.75999450683594\n",
      "epoch 6 \n",
      "---------------------\n",
      "loss:0.216205 [    0/ 60000]\n",
      "loss:0.184574 [ 2560/ 60000]\n",
      "loss:0.102688 [ 5120/ 60000]\n",
      "loss:0.153849 [ 7680/ 60000]\n",
      "loss:0.143812 [10240/ 60000]\n",
      "loss:0.103356 [12800/ 60000]\n",
      "loss:0.218759 [15360/ 60000]\n",
      "loss:0.172216 [17920/ 60000]\n",
      "loss:0.110390 [20480/ 60000]\n",
      "loss:0.124218 [23040/ 60000]\n",
      "loss:0.112228 [25600/ 60000]\n",
      "loss:0.129500 [28160/ 60000]\n",
      "loss:0.106070 [30720/ 60000]\n",
      "loss:0.194920 [33280/ 60000]\n",
      "loss:0.076975 [35840/ 60000]\n",
      "loss:0.131191 [38400/ 60000]\n",
      "loss:0.074830 [40960/ 60000]\n",
      "loss:0.108337 [43520/ 60000]\n",
      "loss:0.123376 [46080/ 60000]\n",
      "loss:0.124685 [48640/ 60000]\n",
      "loss:0.128393 [51200/ 60000]\n",
      "loss:0.101908 [53760/ 60000]\n",
      "loss:0.119688 [56320/ 60000]\n",
      "loss:0.082662 [58880/ 60000]\n",
      "test: acc 96.62999725341797\n",
      "epoch 7 \n",
      "---------------------\n",
      "loss:0.175727 [    0/ 60000]\n",
      "loss:0.089912 [ 2560/ 60000]\n",
      "loss:0.147450 [ 5120/ 60000]\n",
      "loss:0.115814 [ 7680/ 60000]\n",
      "loss:0.121362 [10240/ 60000]\n",
      "loss:0.153296 [12800/ 60000]\n",
      "loss:0.096856 [15360/ 60000]\n",
      "loss:0.097669 [17920/ 60000]\n",
      "loss:0.086047 [20480/ 60000]\n",
      "loss:0.134369 [23040/ 60000]\n",
      "loss:0.132631 [25600/ 60000]\n",
      "loss:0.127503 [28160/ 60000]\n",
      "loss:0.090360 [30720/ 60000]\n",
      "loss:0.093243 [33280/ 60000]\n",
      "loss:0.080752 [35840/ 60000]\n",
      "loss:0.087486 [38400/ 60000]\n",
      "loss:0.155732 [40960/ 60000]\n",
      "loss:0.088209 [43520/ 60000]\n",
      "loss:0.145675 [46080/ 60000]\n",
      "loss:0.042047 [48640/ 60000]\n",
      "loss:0.103104 [51200/ 60000]\n",
      "loss:0.120268 [53760/ 60000]\n",
      "loss:0.086844 [56320/ 60000]\n",
      "loss:0.117719 [58880/ 60000]\n",
      "test: acc 97.05999755859375\n",
      "epoch 8 \n",
      "---------------------\n",
      "loss:0.058686 [    0/ 60000]\n",
      "loss:0.082513 [ 2560/ 60000]\n",
      "loss:0.058904 [ 5120/ 60000]\n",
      "loss:0.107983 [ 7680/ 60000]\n",
      "loss:0.137530 [10240/ 60000]\n",
      "loss:0.063948 [12800/ 60000]\n",
      "loss:0.131172 [15360/ 60000]\n",
      "loss:0.097181 [17920/ 60000]\n",
      "loss:0.141552 [20480/ 60000]\n",
      "loss:0.065517 [23040/ 60000]\n",
      "loss:0.097138 [25600/ 60000]\n",
      "loss:0.069218 [28160/ 60000]\n",
      "loss:0.135513 [30720/ 60000]\n",
      "loss:0.065298 [33280/ 60000]\n",
      "loss:0.101552 [35840/ 60000]\n",
      "loss:0.111489 [38400/ 60000]\n",
      "loss:0.065227 [40960/ 60000]\n",
      "loss:0.108277 [43520/ 60000]\n",
      "loss:0.102134 [46080/ 60000]\n",
      "loss:0.109222 [48640/ 60000]\n",
      "loss:0.093675 [51200/ 60000]\n",
      "loss:0.126632 [53760/ 60000]\n",
      "loss:0.120561 [56320/ 60000]\n",
      "loss:0.080795 [58880/ 60000]\n",
      "test: acc 97.37999725341797\n",
      "epoch 9 \n",
      "---------------------\n",
      "loss:0.138935 [    0/ 60000]\n",
      "loss:0.039640 [ 2560/ 60000]\n",
      "loss:0.062890 [ 5120/ 60000]\n",
      "loss:0.072823 [ 7680/ 60000]\n",
      "loss:0.109049 [10240/ 60000]\n",
      "loss:0.081240 [12800/ 60000]\n",
      "loss:0.059310 [15360/ 60000]\n",
      "loss:0.072267 [17920/ 60000]\n",
      "loss:0.074509 [20480/ 60000]\n",
      "loss:0.070266 [23040/ 60000]\n",
      "loss:0.115667 [25600/ 60000]\n",
      "loss:0.117033 [28160/ 60000]\n",
      "loss:0.070881 [30720/ 60000]\n",
      "loss:0.053849 [33280/ 60000]\n",
      "loss:0.065870 [35840/ 60000]\n",
      "loss:0.077366 [38400/ 60000]\n",
      "loss:0.143793 [40960/ 60000]\n",
      "loss:0.034894 [43520/ 60000]\n",
      "loss:0.075597 [46080/ 60000]\n",
      "loss:0.088701 [48640/ 60000]\n",
      "loss:0.100920 [51200/ 60000]\n",
      "loss:0.076284 [53760/ 60000]\n",
      "loss:0.096147 [56320/ 60000]\n",
      "loss:0.112764 [58880/ 60000]\n",
      "test: acc 97.54999542236328\n",
      "epoch 10 \n",
      "---------------------\n",
      "loss:0.085446 [    0/ 60000]\n",
      "loss:0.062001 [ 2560/ 60000]\n",
      "loss:0.054173 [ 5120/ 60000]\n",
      "loss:0.105240 [ 7680/ 60000]\n",
      "loss:0.113009 [10240/ 60000]\n",
      "loss:0.046203 [12800/ 60000]\n",
      "loss:0.099561 [15360/ 60000]\n",
      "loss:0.040706 [17920/ 60000]\n",
      "loss:0.046213 [20480/ 60000]\n",
      "loss:0.074789 [23040/ 60000]\n",
      "loss:0.067815 [25600/ 60000]\n",
      "loss:0.069544 [28160/ 60000]\n",
      "loss:0.060155 [30720/ 60000]\n",
      "loss:0.076246 [33280/ 60000]\n",
      "loss:0.041085 [35840/ 60000]\n",
      "loss:0.095353 [38400/ 60000]\n",
      "loss:0.076618 [40960/ 60000]\n",
      "loss:0.068621 [43520/ 60000]\n",
      "loss:0.058566 [46080/ 60000]\n",
      "loss:0.080912 [48640/ 60000]\n",
      "loss:0.060120 [51200/ 60000]\n",
      "loss:0.099420 [53760/ 60000]\n",
      "loss:0.045175 [56320/ 60000]\n",
      "loss:0.110915 [58880/ 60000]\n",
      "test: acc 97.54000091552734\n",
      "epoch 11 \n",
      "---------------------\n",
      "loss:0.072960 [    0/ 60000]\n",
      "loss:0.120051 [ 2560/ 60000]\n",
      "loss:0.103110 [ 5120/ 60000]\n",
      "loss:0.058809 [ 7680/ 60000]\n",
      "loss:0.055432 [10240/ 60000]\n",
      "loss:0.051897 [12800/ 60000]\n",
      "loss:0.060695 [15360/ 60000]\n",
      "loss:0.070894 [17920/ 60000]\n",
      "loss:0.055692 [20480/ 60000]\n",
      "loss:0.057674 [23040/ 60000]\n",
      "loss:0.072705 [25600/ 60000]\n",
      "loss:0.083347 [28160/ 60000]\n",
      "loss:0.036712 [30720/ 60000]\n",
      "loss:0.066348 [33280/ 60000]\n",
      "loss:0.059221 [35840/ 60000]\n",
      "loss:0.074547 [38400/ 60000]\n",
      "loss:0.043062 [40960/ 60000]\n",
      "loss:0.076753 [43520/ 60000]\n",
      "loss:0.076189 [46080/ 60000]\n",
      "loss:0.060782 [48640/ 60000]\n",
      "loss:0.094861 [51200/ 60000]\n",
      "loss:0.113232 [53760/ 60000]\n",
      "loss:0.041591 [56320/ 60000]\n",
      "loss:0.044986 [58880/ 60000]\n",
      "test: acc 98.12999725341797\n",
      "epoch 12 \n",
      "---------------------\n",
      "loss:0.064544 [    0/ 60000]\n",
      "loss:0.072604 [ 2560/ 60000]\n",
      "loss:0.048647 [ 5120/ 60000]\n",
      "loss:0.068772 [ 7680/ 60000]\n",
      "loss:0.082389 [10240/ 60000]\n",
      "loss:0.073654 [12800/ 60000]\n",
      "loss:0.076456 [15360/ 60000]\n",
      "loss:0.066900 [17920/ 60000]\n",
      "loss:0.053764 [20480/ 60000]\n",
      "loss:0.082516 [23040/ 60000]\n",
      "loss:0.097689 [25600/ 60000]\n",
      "loss:0.078051 [28160/ 60000]\n",
      "loss:0.046195 [30720/ 60000]\n",
      "loss:0.047105 [33280/ 60000]\n",
      "loss:0.110433 [35840/ 60000]\n",
      "loss:0.099393 [38400/ 60000]\n",
      "loss:0.050079 [40960/ 60000]\n",
      "loss:0.046518 [43520/ 60000]\n",
      "loss:0.044758 [46080/ 60000]\n",
      "loss:0.058819 [48640/ 60000]\n",
      "loss:0.042468 [51200/ 60000]\n",
      "loss:0.070407 [53760/ 60000]\n",
      "loss:0.076399 [56320/ 60000]\n",
      "loss:0.048704 [58880/ 60000]\n",
      "test: acc 97.93999481201172\n",
      "epoch 13 \n",
      "---------------------\n",
      "loss:0.072637 [    0/ 60000]\n",
      "loss:0.068326 [ 2560/ 60000]\n",
      "loss:0.046960 [ 5120/ 60000]\n",
      "loss:0.025384 [ 7680/ 60000]\n",
      "loss:0.065038 [10240/ 60000]\n",
      "loss:0.051779 [12800/ 60000]\n",
      "loss:0.067074 [15360/ 60000]\n",
      "loss:0.075035 [17920/ 60000]\n",
      "loss:0.054108 [20480/ 60000]\n",
      "loss:0.101110 [23040/ 60000]\n",
      "loss:0.036924 [25600/ 60000]\n",
      "loss:0.033061 [28160/ 60000]\n",
      "loss:0.101324 [30720/ 60000]\n",
      "loss:0.051525 [33280/ 60000]\n",
      "loss:0.069784 [35840/ 60000]\n",
      "loss:0.082729 [38400/ 60000]\n",
      "loss:0.081150 [40960/ 60000]\n",
      "loss:0.090467 [43520/ 60000]\n",
      "loss:0.154258 [46080/ 60000]\n",
      "loss:0.099095 [48640/ 60000]\n",
      "loss:0.031463 [51200/ 60000]\n",
      "loss:0.056142 [53760/ 60000]\n",
      "loss:0.035772 [56320/ 60000]\n",
      "loss:0.087046 [58880/ 60000]\n",
      "test: acc 97.75999450683594\n",
      "epoch 14 \n",
      "---------------------\n",
      "loss:0.049950 [    0/ 60000]\n",
      "loss:0.055537 [ 2560/ 60000]\n",
      "loss:0.093209 [ 5120/ 60000]\n",
      "loss:0.081877 [ 7680/ 60000]\n",
      "loss:0.060686 [10240/ 60000]\n",
      "loss:0.067065 [12800/ 60000]\n",
      "loss:0.042666 [15360/ 60000]\n",
      "loss:0.017355 [17920/ 60000]\n",
      "loss:0.044318 [20480/ 60000]\n",
      "loss:0.044119 [23040/ 60000]\n",
      "loss:0.061671 [25600/ 60000]\n",
      "loss:0.067978 [28160/ 60000]\n",
      "loss:0.079881 [30720/ 60000]\n",
      "loss:0.034629 [33280/ 60000]\n",
      "loss:0.101013 [35840/ 60000]\n",
      "loss:0.057100 [38400/ 60000]\n",
      "loss:0.032811 [40960/ 60000]\n",
      "loss:0.087525 [43520/ 60000]\n",
      "loss:0.035458 [46080/ 60000]\n",
      "loss:0.053278 [48640/ 60000]\n",
      "loss:0.049708 [51200/ 60000]\n",
      "loss:0.029540 [53760/ 60000]\n",
      "loss:0.069665 [56320/ 60000]\n",
      "loss:0.047144 [58880/ 60000]\n",
      "test: acc 98.25\n",
      "epoch 15 \n",
      "---------------------\n",
      "loss:0.048407 [    0/ 60000]\n",
      "loss:0.087052 [ 2560/ 60000]\n",
      "loss:0.029266 [ 5120/ 60000]\n",
      "loss:0.040419 [ 7680/ 60000]\n",
      "loss:0.064805 [10240/ 60000]\n",
      "loss:0.041474 [12800/ 60000]\n",
      "loss:0.048142 [15360/ 60000]\n",
      "loss:0.038061 [17920/ 60000]\n",
      "loss:0.019098 [20480/ 60000]\n",
      "loss:0.066281 [23040/ 60000]\n",
      "loss:0.032573 [25600/ 60000]\n",
      "loss:0.042315 [28160/ 60000]\n",
      "loss:0.069541 [30720/ 60000]\n",
      "loss:0.041315 [33280/ 60000]\n",
      "loss:0.068300 [35840/ 60000]\n",
      "loss:0.063051 [38400/ 60000]\n",
      "loss:0.073083 [40960/ 60000]\n",
      "loss:0.057902 [43520/ 60000]\n",
      "loss:0.064889 [46080/ 60000]\n",
      "loss:0.110642 [48640/ 60000]\n",
      "loss:0.050244 [51200/ 60000]\n",
      "loss:0.059221 [53760/ 60000]\n",
      "loss:0.103956 [56320/ 60000]\n",
      "loss:0.097170 [58880/ 60000]\n",
      "test: acc 98.20999908447266\n",
      "epoch 16 \n",
      "---------------------\n",
      "loss:0.031280 [    0/ 60000]\n",
      "loss:0.042267 [ 2560/ 60000]\n",
      "loss:0.036550 [ 5120/ 60000]\n",
      "loss:0.035299 [ 7680/ 60000]\n",
      "loss:0.053882 [10240/ 60000]\n",
      "loss:0.102170 [12800/ 60000]\n",
      "loss:0.061947 [15360/ 60000]\n",
      "loss:0.032176 [17920/ 60000]\n",
      "loss:0.095090 [20480/ 60000]\n",
      "loss:0.049073 [23040/ 60000]\n",
      "loss:0.024494 [25600/ 60000]\n",
      "loss:0.084376 [28160/ 60000]\n",
      "loss:0.065248 [30720/ 60000]\n",
      "loss:0.033471 [33280/ 60000]\n",
      "loss:0.032116 [35840/ 60000]\n",
      "loss:0.072762 [38400/ 60000]\n",
      "loss:0.021038 [40960/ 60000]\n",
      "loss:0.101700 [43520/ 60000]\n",
      "loss:0.052953 [46080/ 60000]\n",
      "loss:0.056768 [48640/ 60000]\n",
      "loss:0.043968 [51200/ 60000]\n",
      "loss:0.045496 [53760/ 60000]\n",
      "loss:0.068481 [56320/ 60000]\n",
      "loss:0.067864 [58880/ 60000]\n",
      "test: acc 98.31999969482422\n",
      "epoch 17 \n",
      "---------------------\n",
      "loss:0.039188 [    0/ 60000]\n",
      "loss:0.032133 [ 2560/ 60000]\n",
      "loss:0.055962 [ 5120/ 60000]\n",
      "loss:0.070269 [ 7680/ 60000]\n",
      "loss:0.024032 [10240/ 60000]\n",
      "loss:0.048045 [12800/ 60000]\n",
      "loss:0.077849 [15360/ 60000]\n",
      "loss:0.103283 [17920/ 60000]\n",
      "loss:0.059849 [20480/ 60000]\n",
      "loss:0.021496 [23040/ 60000]\n",
      "loss:0.059829 [25600/ 60000]\n",
      "loss:0.035122 [28160/ 60000]\n",
      "loss:0.051045 [30720/ 60000]\n",
      "loss:0.052058 [33280/ 60000]\n",
      "loss:0.098471 [35840/ 60000]\n",
      "loss:0.096158 [38400/ 60000]\n",
      "loss:0.065382 [40960/ 60000]\n",
      "loss:0.068695 [43520/ 60000]\n",
      "loss:0.034538 [46080/ 60000]\n",
      "loss:0.014080 [48640/ 60000]\n",
      "loss:0.012069 [51200/ 60000]\n",
      "loss:0.067213 [53760/ 60000]\n",
      "loss:0.025862 [56320/ 60000]\n",
      "loss:0.067824 [58880/ 60000]\n",
      "test: acc 98.3699951171875\n",
      "epoch 18 \n",
      "---------------------\n",
      "loss:0.038706 [    0/ 60000]\n",
      "loss:0.029877 [ 2560/ 60000]\n",
      "loss:0.023762 [ 5120/ 60000]\n",
      "loss:0.076997 [ 7680/ 60000]\n",
      "loss:0.068062 [10240/ 60000]\n",
      "loss:0.090843 [12800/ 60000]\n",
      "loss:0.039254 [15360/ 60000]\n",
      "loss:0.044716 [17920/ 60000]\n",
      "loss:0.058429 [20480/ 60000]\n",
      "loss:0.013366 [23040/ 60000]\n",
      "loss:0.038463 [25600/ 60000]\n",
      "loss:0.042156 [28160/ 60000]\n",
      "loss:0.055271 [30720/ 60000]\n",
      "loss:0.032645 [33280/ 60000]\n",
      "loss:0.043102 [35840/ 60000]\n",
      "loss:0.025981 [38400/ 60000]\n",
      "loss:0.072235 [40960/ 60000]\n",
      "loss:0.117348 [43520/ 60000]\n",
      "loss:0.049105 [46080/ 60000]\n",
      "loss:0.042861 [48640/ 60000]\n",
      "loss:0.039035 [51200/ 60000]\n",
      "loss:0.026921 [53760/ 60000]\n",
      "loss:0.038469 [56320/ 60000]\n",
      "loss:0.047274 [58880/ 60000]\n",
      "test: acc 98.48999786376953\n",
      "epoch 19 \n",
      "---------------------\n",
      "loss:0.048940 [    0/ 60000]\n",
      "loss:0.023133 [ 2560/ 60000]\n",
      "loss:0.030989 [ 5120/ 60000]\n",
      "loss:0.060055 [ 7680/ 60000]\n",
      "loss:0.042533 [10240/ 60000]\n",
      "loss:0.059153 [12800/ 60000]\n",
      "loss:0.052853 [15360/ 60000]\n",
      "loss:0.075778 [17920/ 60000]\n",
      "loss:0.045631 [20480/ 60000]\n",
      "loss:0.045745 [23040/ 60000]\n",
      "loss:0.026185 [25600/ 60000]\n",
      "loss:0.013891 [28160/ 60000]\n",
      "loss:0.036519 [30720/ 60000]\n",
      "loss:0.040881 [33280/ 60000]\n",
      "loss:0.055769 [35840/ 60000]\n",
      "loss:0.016924 [38400/ 60000]\n",
      "loss:0.030602 [40960/ 60000]\n",
      "loss:0.026200 [43520/ 60000]\n",
      "loss:0.053184 [46080/ 60000]\n",
      "loss:0.036198 [48640/ 60000]\n",
      "loss:0.088618 [51200/ 60000]\n",
      "loss:0.012719 [53760/ 60000]\n",
      "loss:0.034225 [56320/ 60000]\n",
      "loss:0.028965 [58880/ 60000]\n",
      "test: acc 98.37999725341797\n"
     ]
    }
   ],
   "source": [
    "net = LeNet1().to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "net.apply(init_weights)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\n",
    "        f\"epoch {epoch} \\n---------------------\"\n",
    "    )\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(inputs)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d}/ 60000]\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        for (image, label) in test_dataloader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            output = net(image)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            acc += (pred == label).sum()\n",
    "\n",
    "        print(f\"test: acc {100 * acc / total}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T10:48:31.357194500Z",
     "start_time": "2024-02-29T10:45:42.153566200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
