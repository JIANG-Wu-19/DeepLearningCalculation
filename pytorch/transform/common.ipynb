{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"../data/change/train/ants_image/1030023514_aad5c608f9.jpg\"\n",
    "image_PIL=Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_PIL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toTensor=transforms.ToTensor()\n",
    "image_tensor=toTensor(image_PIL)\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=SummaryWriter(\"logs\")\n",
    "writer.add_image(\"tensor\",image_tensor,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm=transforms.Normalize([0.01,0.01,0.01],[1,1,1])\n",
    "image_norm=norm(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image(\"tensor\",image_norm,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 333)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_PIL.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize=transforms.Resize((512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resize=resize(image_PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resize.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.01,0.01,0.01],[1,1,1]),\n",
    "    transforms.Resize((512,512),antialias=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.01, 0.01, 0.01], std=[1, 1, 1])\n",
       "    Resize(size=(512, 512), interpolation=bilinear, max_size=None, antialias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.JpegImagePlugin.JpegImageFile"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_com=compose(image_PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6841, 0.7522, 0.8322,  ..., 0.8389, 0.8049, 0.7822],\n",
       "         [0.6580, 0.7369, 0.8243,  ..., 0.8399, 0.8221, 0.8120],\n",
       "         [0.6183, 0.7144, 0.8018,  ..., 0.8407, 0.8437, 0.8498],\n",
       "         ...,\n",
       "         [0.8567, 0.8628, 0.8409,  ..., 0.8445, 0.8291, 0.8111],\n",
       "         [0.8363, 0.8457, 0.8258,  ..., 0.8502, 0.8348, 0.8199],\n",
       "         [0.8214, 0.8289, 0.8108,  ..., 0.8557, 0.8406, 0.8292]],\n",
       "\n",
       "        [[0.6684, 0.7441, 0.8465,  ..., 0.8232, 0.7888, 0.7547],\n",
       "         [0.6367, 0.7160, 0.8221,  ..., 0.8279, 0.8099, 0.7939],\n",
       "         [0.5958, 0.6796, 0.7799,  ..., 0.8299, 0.8334, 0.8395],\n",
       "         ...,\n",
       "         [0.8435, 0.8392, 0.8132,  ..., 0.8096, 0.8020, 0.7939],\n",
       "         [0.8245, 0.8245, 0.7967,  ..., 0.8196, 0.8138, 0.8042],\n",
       "         [0.8096, 0.8096, 0.7801,  ..., 0.8290, 0.8249, 0.8135]],\n",
       "\n",
       "        [[0.5704, 0.6612, 0.7568,  ..., 0.7169, 0.6782, 0.7312],\n",
       "         [0.5517, 0.6156, 0.7383,  ..., 0.7442, 0.7241, 0.7573],\n",
       "         [0.5198, 0.5596, 0.7026,  ..., 0.7774, 0.7792, 0.7910],\n",
       "         ...,\n",
       "         [0.7783, 0.7934, 0.7528,  ..., 0.7884, 0.7692, 0.7513],\n",
       "         [0.7743, 0.7893, 0.7453,  ..., 0.7972, 0.7800, 0.7611],\n",
       "         [0.7743, 0.7857, 0.7381,  ..., 0.8048, 0.7893, 0.7704]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random=transforms.RandomCrop(256)\n",
    "compose=transforms.Compose([\n",
    "    random,\n",
    "    toTensor\n",
    "])\n",
    "for i in range(10):\n",
    "    img_crop=compose(image_PIL)\n",
    "    # print(img_crop)\n",
    "    writer.add_image(\"crop\",img_crop,i)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
