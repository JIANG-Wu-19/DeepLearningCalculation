{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ResNet import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize([96,96]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_set=torchvision.datasets.CIFAR10(root=\"../data\",train=True,transform=transform,download=False)\n",
    "test_set=torchvision.datasets.CIFAR10(root=\"../data\",train=False,transform=transform,download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img,label=train_set[0]\n",
    "# img.shape,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "lr=0.1\n",
    "epoch=20\n",
    "writer=SummaryWriter(\"logs\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trainLoader=DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=0,drop_last=False)\n",
    "testLoader=DataLoader(test_set,batch_size=batch_size,shuffle=True,num_workers=0,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ResNet().to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "model.apply(init_weights)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=lr,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainLoader,model,loss_fn,optimizer):\n",
    "    print(f\"training on:{device}\")\n",
    "    # model=model.to(device)\n",
    "    size=len(trainLoader.dataset)\n",
    "    \n",
    "    for batch,(X,y) in enumerate(trainLoader):\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        pred=model(X)\n",
    "        loss=loss_fn(pred,y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch%10==0:\n",
    "            loss,current=loss.item(),batch*len(X)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_correct=0\n",
    "def test(testLoader, model, loss_fn,max_correct):\n",
    "    # model = model.to(device)\n",
    "    size = len(testLoader.dataset)\n",
    "    num_batches = len(testLoader)\n",
    "    # test_loss, correct = 0, 0\n",
    "    acc=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        for X, y in testLoader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            _,pred=torch.max(pred.data,1)\n",
    "            total+=y.size(0)\n",
    "            acc+=(pred==y).sum()\n",
    "            \n",
    "\n",
    "    # test_loss /= num_batches\n",
    "\n",
    "    # correct /= size\n",
    "    \n",
    "    # if correct>max_correct:\n",
    "    #     torch.save(model.state_dict(),'LeNet.params')\n",
    "    #     max_correct=correct\n",
    "\n",
    "    # print(f\"test error:\\n accuracy:{(100 * correct):>0.1f}%,avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    print(f\"test: acc {100 * acc / total}\")\n",
    "    return acc/total\n",
    "    # return max_correct,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:2.812350 [    0/50000]\n",
      "loss:2.872330 [ 2560/50000]\n",
      "loss:2.262649 [ 5120/50000]\n",
      "loss:2.125688 [ 7680/50000]\n",
      "loss:2.286537 [10240/50000]\n",
      "loss:2.044193 [12800/50000]\n",
      "loss:1.958902 [15360/50000]\n",
      "loss:1.995030 [17920/50000]\n",
      "loss:1.866028 [20480/50000]\n",
      "loss:1.842914 [23040/50000]\n",
      "loss:1.908438 [25600/50000]\n",
      "loss:1.835117 [28160/50000]\n",
      "loss:1.630613 [30720/50000]\n",
      "loss:1.744376 [33280/50000]\n",
      "loss:1.574750 [35840/50000]\n",
      "loss:1.579237 [38400/50000]\n",
      "loss:1.513280 [40960/50000]\n",
      "loss:1.568063 [43520/50000]\n",
      "loss:1.508846 [46080/50000]\n",
      "loss:1.492773 [48640/50000]\n",
      "test: acc 44.47999954223633\n",
      "epoch 2 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:1.570405 [    0/50000]\n",
      "loss:1.518711 [ 2560/50000]\n",
      "loss:1.392497 [ 5120/50000]\n",
      "loss:1.347169 [ 7680/50000]\n",
      "loss:1.589877 [10240/50000]\n",
      "loss:1.235840 [12800/50000]\n",
      "loss:1.451742 [15360/50000]\n",
      "loss:1.435752 [17920/50000]\n",
      "loss:1.414106 [20480/50000]\n",
      "loss:1.286387 [23040/50000]\n",
      "loss:1.397709 [25600/50000]\n",
      "loss:1.350814 [28160/50000]\n",
      "loss:1.159405 [30720/50000]\n",
      "loss:1.276000 [33280/50000]\n",
      "loss:1.175728 [35840/50000]\n",
      "loss:1.395065 [38400/50000]\n",
      "loss:1.233698 [40960/50000]\n",
      "loss:1.168712 [43520/50000]\n",
      "loss:1.182241 [46080/50000]\n",
      "loss:1.184792 [48640/50000]\n",
      "test: acc 55.96999740600586\n",
      "epoch 3 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:1.145025 [    0/50000]\n",
      "loss:1.035762 [ 2560/50000]\n",
      "loss:1.127975 [ 5120/50000]\n",
      "loss:1.138676 [ 7680/50000]\n",
      "loss:1.109341 [10240/50000]\n",
      "loss:1.089340 [12800/50000]\n",
      "loss:1.093603 [15360/50000]\n",
      "loss:0.903368 [17920/50000]\n",
      "loss:1.033961 [20480/50000]\n",
      "loss:1.133918 [23040/50000]\n",
      "loss:1.003837 [25600/50000]\n",
      "loss:1.089355 [28160/50000]\n",
      "loss:1.022171 [30720/50000]\n",
      "loss:1.110350 [33280/50000]\n",
      "loss:1.019782 [35840/50000]\n",
      "loss:0.998890 [38400/50000]\n",
      "loss:0.891633 [40960/50000]\n",
      "loss:0.895701 [43520/50000]\n",
      "loss:1.139416 [46080/50000]\n",
      "loss:1.095113 [48640/50000]\n",
      "test: acc 63.939998626708984\n",
      "epoch 4 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:1.034830 [    0/50000]\n",
      "loss:0.955508 [ 2560/50000]\n",
      "loss:1.012397 [ 5120/50000]\n",
      "loss:0.890754 [ 7680/50000]\n",
      "loss:0.826515 [10240/50000]\n",
      "loss:0.915952 [12800/50000]\n",
      "loss:0.942746 [15360/50000]\n",
      "loss:0.925478 [17920/50000]\n",
      "loss:0.791904 [20480/50000]\n",
      "loss:0.828661 [23040/50000]\n",
      "loss:0.870922 [25600/50000]\n",
      "loss:0.875823 [28160/50000]\n",
      "loss:0.820176 [30720/50000]\n",
      "loss:0.866004 [33280/50000]\n",
      "loss:0.982282 [35840/50000]\n",
      "loss:0.802517 [38400/50000]\n",
      "loss:0.829087 [40960/50000]\n",
      "loss:0.956173 [43520/50000]\n",
      "loss:0.872650 [46080/50000]\n",
      "loss:0.716082 [48640/50000]\n",
      "test: acc 69.38999938964844\n",
      "epoch 5 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.729141 [    0/50000]\n",
      "loss:0.782788 [ 2560/50000]\n",
      "loss:0.713506 [ 5120/50000]\n",
      "loss:0.701929 [ 7680/50000]\n",
      "loss:0.861995 [10240/50000]\n",
      "loss:0.567462 [12800/50000]\n",
      "loss:0.737374 [15360/50000]\n",
      "loss:0.752710 [17920/50000]\n",
      "loss:0.793142 [20480/50000]\n",
      "loss:0.805064 [23040/50000]\n",
      "loss:0.761821 [25600/50000]\n",
      "loss:0.825806 [28160/50000]\n",
      "loss:0.822787 [30720/50000]\n",
      "loss:0.635333 [33280/50000]\n",
      "loss:0.649110 [35840/50000]\n",
      "loss:0.773080 [38400/50000]\n",
      "loss:0.697251 [40960/50000]\n",
      "loss:0.690355 [43520/50000]\n",
      "loss:0.797583 [46080/50000]\n",
      "loss:0.678422 [48640/50000]\n",
      "test: acc 72.56999969482422\n",
      "epoch 6 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.497096 [    0/50000]\n",
      "loss:0.510478 [ 2560/50000]\n",
      "loss:0.514765 [ 5120/50000]\n",
      "loss:0.588061 [ 7680/50000]\n",
      "loss:0.591111 [10240/50000]\n",
      "loss:0.608846 [12800/50000]\n",
      "loss:0.523503 [15360/50000]\n",
      "loss:0.558571 [17920/50000]\n",
      "loss:0.663680 [20480/50000]\n",
      "loss:0.672172 [23040/50000]\n",
      "loss:0.590350 [25600/50000]\n",
      "loss:0.604386 [28160/50000]\n",
      "loss:0.604577 [30720/50000]\n",
      "loss:0.659209 [33280/50000]\n",
      "loss:0.572802 [35840/50000]\n",
      "loss:0.528078 [38400/50000]\n",
      "loss:0.584783 [40960/50000]\n",
      "loss:0.594447 [43520/50000]\n",
      "loss:0.609429 [46080/50000]\n",
      "loss:0.592829 [48640/50000]\n",
      "test: acc 73.3699951171875\n",
      "epoch 7 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.443769 [    0/50000]\n",
      "loss:0.396859 [ 2560/50000]\n",
      "loss:0.434920 [ 5120/50000]\n",
      "loss:0.467868 [ 7680/50000]\n",
      "loss:0.441882 [10240/50000]\n",
      "loss:0.452772 [12800/50000]\n",
      "loss:0.530463 [15360/50000]\n",
      "loss:0.523120 [17920/50000]\n",
      "loss:0.432095 [20480/50000]\n",
      "loss:0.423461 [23040/50000]\n",
      "loss:0.474513 [25600/50000]\n",
      "loss:0.458732 [28160/50000]\n",
      "loss:0.410511 [30720/50000]\n",
      "loss:0.542828 [33280/50000]\n",
      "loss:0.492715 [35840/50000]\n",
      "loss:0.572613 [38400/50000]\n",
      "loss:0.527137 [40960/50000]\n",
      "loss:0.549615 [43520/50000]\n",
      "loss:0.526377 [46080/50000]\n",
      "loss:0.429484 [48640/50000]\n",
      "test: acc 74.75999450683594\n",
      "epoch 8 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.365709 [    0/50000]\n",
      "loss:0.269352 [ 2560/50000]\n",
      "loss:0.364515 [ 5120/50000]\n",
      "loss:0.264205 [ 7680/50000]\n",
      "loss:0.324484 [10240/50000]\n",
      "loss:0.310646 [12800/50000]\n",
      "loss:0.466353 [15360/50000]\n",
      "loss:0.407594 [17920/50000]\n",
      "loss:0.273447 [20480/50000]\n",
      "loss:0.363747 [23040/50000]\n",
      "loss:0.399127 [25600/50000]\n",
      "loss:0.328986 [28160/50000]\n",
      "loss:0.464872 [30720/50000]\n",
      "loss:0.375225 [33280/50000]\n",
      "loss:0.454635 [35840/50000]\n",
      "loss:0.316268 [38400/50000]\n",
      "loss:0.442761 [40960/50000]\n",
      "loss:0.488205 [43520/50000]\n",
      "loss:0.438726 [46080/50000]\n",
      "loss:0.351916 [48640/50000]\n",
      "test: acc 74.55999755859375\n",
      "epoch 9 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.284612 [    0/50000]\n",
      "loss:0.187216 [ 2560/50000]\n",
      "loss:0.283772 [ 5120/50000]\n",
      "loss:0.223640 [ 7680/50000]\n",
      "loss:0.324031 [10240/50000]\n",
      "loss:0.348323 [12800/50000]\n",
      "loss:0.333001 [15360/50000]\n",
      "loss:0.198636 [17920/50000]\n",
      "loss:0.291655 [20480/50000]\n",
      "loss:0.382459 [23040/50000]\n",
      "loss:0.264844 [25600/50000]\n",
      "loss:0.349777 [28160/50000]\n",
      "loss:0.443238 [30720/50000]\n",
      "loss:0.345321 [33280/50000]\n",
      "loss:0.273450 [35840/50000]\n",
      "loss:0.302151 [38400/50000]\n",
      "loss:0.375978 [40960/50000]\n",
      "loss:0.253308 [43520/50000]\n",
      "loss:0.319000 [46080/50000]\n",
      "loss:0.302630 [48640/50000]\n",
      "test: acc 74.69999694824219\n",
      "epoch 10 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.200151 [    0/50000]\n",
      "loss:0.300276 [ 2560/50000]\n",
      "loss:0.233380 [ 5120/50000]\n",
      "loss:0.153762 [ 7680/50000]\n",
      "loss:0.146926 [10240/50000]\n",
      "loss:0.128674 [12800/50000]\n",
      "loss:0.215980 [15360/50000]\n",
      "loss:0.245936 [17920/50000]\n",
      "loss:0.205292 [20480/50000]\n",
      "loss:0.179478 [23040/50000]\n",
      "loss:0.270682 [25600/50000]\n",
      "loss:0.141985 [28160/50000]\n",
      "loss:0.174952 [30720/50000]\n",
      "loss:0.224219 [33280/50000]\n",
      "loss:0.224773 [35840/50000]\n",
      "loss:0.191302 [38400/50000]\n",
      "loss:0.291449 [40960/50000]\n",
      "loss:0.255522 [43520/50000]\n",
      "loss:0.307256 [46080/50000]\n",
      "loss:0.237064 [48640/50000]\n",
      "test: acc 75.11000061035156\n",
      "epoch 11 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.118404 [    0/50000]\n",
      "loss:0.118995 [ 2560/50000]\n",
      "loss:0.167942 [ 5120/50000]\n",
      "loss:0.097555 [ 7680/50000]\n",
      "loss:0.113918 [10240/50000]\n",
      "loss:0.176907 [12800/50000]\n",
      "loss:0.145699 [15360/50000]\n",
      "loss:0.156921 [17920/50000]\n",
      "loss:0.218188 [20480/50000]\n",
      "loss:0.226558 [23040/50000]\n",
      "loss:0.159820 [25600/50000]\n",
      "loss:0.106598 [28160/50000]\n",
      "loss:0.215288 [30720/50000]\n",
      "loss:0.185910 [33280/50000]\n",
      "loss:0.186076 [35840/50000]\n",
      "loss:0.192724 [38400/50000]\n",
      "loss:0.128181 [40960/50000]\n",
      "loss:0.224609 [43520/50000]\n",
      "loss:0.186495 [46080/50000]\n",
      "loss:0.144667 [48640/50000]\n",
      "test: acc 74.90999603271484\n",
      "epoch 12 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.100179 [    0/50000]\n",
      "loss:0.098399 [ 2560/50000]\n",
      "loss:0.145297 [ 5120/50000]\n",
      "loss:0.135259 [ 7680/50000]\n",
      "loss:0.123746 [10240/50000]\n",
      "loss:0.120585 [12800/50000]\n",
      "loss:0.096331 [15360/50000]\n",
      "loss:0.131837 [17920/50000]\n",
      "loss:0.133054 [20480/50000]\n",
      "loss:0.190531 [23040/50000]\n",
      "loss:0.135505 [25600/50000]\n",
      "loss:0.084183 [28160/50000]\n",
      "loss:0.129000 [30720/50000]\n",
      "loss:0.185825 [33280/50000]\n",
      "loss:0.114102 [35840/50000]\n",
      "loss:0.191177 [38400/50000]\n",
      "loss:0.123909 [40960/50000]\n",
      "loss:0.122739 [43520/50000]\n",
      "loss:0.131481 [46080/50000]\n",
      "loss:0.133852 [48640/50000]\n",
      "test: acc 75.5\n",
      "epoch 13 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.076417 [    0/50000]\n",
      "loss:0.132919 [ 2560/50000]\n",
      "loss:0.082739 [ 5120/50000]\n",
      "loss:0.157194 [ 7680/50000]\n",
      "loss:0.074680 [10240/50000]\n",
      "loss:0.066255 [12800/50000]\n",
      "loss:0.110899 [15360/50000]\n",
      "loss:0.066242 [17920/50000]\n",
      "loss:0.151079 [20480/50000]\n",
      "loss:0.108330 [23040/50000]\n",
      "loss:0.087682 [25600/50000]\n",
      "loss:0.132506 [28160/50000]\n",
      "loss:0.104507 [30720/50000]\n",
      "loss:0.146392 [33280/50000]\n",
      "loss:0.157464 [35840/50000]\n",
      "loss:0.094694 [38400/50000]\n",
      "loss:0.094886 [40960/50000]\n",
      "loss:0.120729 [43520/50000]\n",
      "loss:0.162184 [46080/50000]\n",
      "loss:0.102081 [48640/50000]\n",
      "test: acc 76.52999877929688\n",
      "epoch 14 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.047291 [    0/50000]\n",
      "loss:0.140492 [ 2560/50000]\n",
      "loss:0.060296 [ 5120/50000]\n",
      "loss:0.056883 [ 7680/50000]\n",
      "loss:0.062643 [10240/50000]\n",
      "loss:0.105170 [12800/50000]\n",
      "loss:0.054398 [15360/50000]\n",
      "loss:0.031782 [17920/50000]\n",
      "loss:0.137467 [20480/50000]\n",
      "loss:0.059507 [23040/50000]\n",
      "loss:0.067766 [25600/50000]\n",
      "loss:0.071307 [28160/50000]\n",
      "loss:0.107444 [30720/50000]\n",
      "loss:0.083751 [33280/50000]\n",
      "loss:0.132058 [35840/50000]\n",
      "loss:0.104160 [38400/50000]\n",
      "loss:0.073779 [40960/50000]\n",
      "loss:0.073059 [43520/50000]\n",
      "loss:0.109378 [46080/50000]\n",
      "loss:0.077632 [48640/50000]\n",
      "test: acc 76.16999816894531\n",
      "epoch 15 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.101560 [    0/50000]\n",
      "loss:0.087099 [ 2560/50000]\n",
      "loss:0.041708 [ 5120/50000]\n",
      "loss:0.065177 [ 7680/50000]\n",
      "loss:0.051611 [10240/50000]\n",
      "loss:0.077344 [12800/50000]\n",
      "loss:0.040242 [15360/50000]\n",
      "loss:0.033374 [17920/50000]\n",
      "loss:0.047551 [20480/50000]\n",
      "loss:0.037032 [23040/50000]\n",
      "loss:0.097751 [25600/50000]\n",
      "loss:0.062314 [28160/50000]\n",
      "loss:0.132485 [30720/50000]\n",
      "loss:0.057855 [33280/50000]\n",
      "loss:0.050371 [35840/50000]\n",
      "loss:0.052639 [38400/50000]\n",
      "loss:0.063069 [40960/50000]\n",
      "loss:0.041474 [43520/50000]\n",
      "loss:0.042220 [46080/50000]\n",
      "loss:0.099245 [48640/50000]\n",
      "test: acc 76.72000122070312\n",
      "epoch 16 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.017748 [    0/50000]\n",
      "loss:0.033318 [ 2560/50000]\n",
      "loss:0.037971 [ 5120/50000]\n",
      "loss:0.037602 [ 7680/50000]\n",
      "loss:0.076582 [10240/50000]\n",
      "loss:0.036770 [12800/50000]\n",
      "loss:0.059998 [15360/50000]\n",
      "loss:0.067606 [17920/50000]\n",
      "loss:0.046591 [20480/50000]\n",
      "loss:0.064748 [23040/50000]\n",
      "loss:0.110314 [25600/50000]\n",
      "loss:0.054089 [28160/50000]\n",
      "loss:0.060286 [30720/50000]\n",
      "loss:0.059907 [33280/50000]\n",
      "loss:0.094997 [35840/50000]\n",
      "loss:0.103915 [38400/50000]\n",
      "loss:0.062115 [40960/50000]\n",
      "loss:0.093105 [43520/50000]\n",
      "loss:0.116341 [46080/50000]\n",
      "loss:0.098108 [48640/50000]\n",
      "test: acc 75.79999542236328\n",
      "epoch 17 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.081603 [    0/50000]\n",
      "loss:0.087817 [ 2560/50000]\n",
      "loss:0.102547 [ 5120/50000]\n",
      "loss:0.014014 [ 7680/50000]\n",
      "loss:0.082071 [10240/50000]\n",
      "loss:0.027293 [12800/50000]\n",
      "loss:0.045273 [15360/50000]\n",
      "loss:0.043893 [17920/50000]\n",
      "loss:0.037330 [20480/50000]\n",
      "loss:0.052053 [23040/50000]\n",
      "loss:0.047300 [25600/50000]\n",
      "loss:0.047580 [28160/50000]\n",
      "loss:0.053107 [30720/50000]\n",
      "loss:0.066368 [33280/50000]\n",
      "loss:0.093538 [35840/50000]\n",
      "loss:0.020557 [38400/50000]\n",
      "loss:0.036769 [40960/50000]\n",
      "loss:0.043729 [43520/50000]\n",
      "loss:0.095546 [46080/50000]\n",
      "loss:0.036011 [48640/50000]\n",
      "test: acc 76.62999725341797\n",
      "epoch 18 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.053859 [    0/50000]\n",
      "loss:0.058604 [ 2560/50000]\n",
      "loss:0.024805 [ 5120/50000]\n",
      "loss:0.044467 [ 7680/50000]\n",
      "loss:0.039460 [10240/50000]\n",
      "loss:0.068047 [12800/50000]\n",
      "loss:0.021023 [15360/50000]\n",
      "loss:0.044755 [17920/50000]\n",
      "loss:0.040020 [20480/50000]\n",
      "loss:0.040337 [23040/50000]\n",
      "loss:0.042825 [25600/50000]\n",
      "loss:0.004798 [28160/50000]\n",
      "loss:0.048166 [30720/50000]\n",
      "loss:0.035625 [33280/50000]\n",
      "loss:0.030249 [35840/50000]\n",
      "loss:0.062579 [38400/50000]\n",
      "loss:0.094228 [40960/50000]\n",
      "loss:0.049356 [43520/50000]\n",
      "loss:0.018854 [46080/50000]\n",
      "loss:0.045378 [48640/50000]\n",
      "test: acc 77.23999786376953\n",
      "epoch 19 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.015092 [    0/50000]\n",
      "loss:0.032490 [ 2560/50000]\n",
      "loss:0.021208 [ 5120/50000]\n",
      "loss:0.024473 [ 7680/50000]\n",
      "loss:0.049901 [10240/50000]\n",
      "loss:0.065802 [12800/50000]\n",
      "loss:0.031008 [15360/50000]\n",
      "loss:0.010192 [17920/50000]\n",
      "loss:0.069533 [20480/50000]\n",
      "loss:0.017307 [23040/50000]\n",
      "loss:0.049780 [25600/50000]\n",
      "loss:0.036255 [28160/50000]\n",
      "loss:0.058544 [30720/50000]\n",
      "loss:0.029221 [33280/50000]\n",
      "loss:0.057004 [35840/50000]\n",
      "loss:0.036969 [38400/50000]\n",
      "loss:0.022076 [40960/50000]\n",
      "loss:0.021533 [43520/50000]\n",
      "loss:0.034146 [46080/50000]\n",
      "loss:0.045242 [48640/50000]\n",
      "test: acc 76.20999908447266\n",
      "epoch 20 \n",
      "----------------------------------------------\n",
      "training on:cuda\n",
      "loss:0.023969 [    0/50000]\n",
      "loss:0.026403 [ 2560/50000]\n",
      "loss:0.015078 [ 5120/50000]\n",
      "loss:0.037722 [ 7680/50000]\n",
      "loss:0.036929 [10240/50000]\n",
      "loss:0.025289 [12800/50000]\n",
      "loss:0.007704 [15360/50000]\n",
      "loss:0.022470 [17920/50000]\n",
      "loss:0.017487 [20480/50000]\n",
      "loss:0.049883 [23040/50000]\n",
      "loss:0.033451 [25600/50000]\n",
      "loss:0.024303 [28160/50000]\n",
      "loss:0.026689 [30720/50000]\n",
      "loss:0.038703 [33280/50000]\n",
      "loss:0.022333 [35840/50000]\n",
      "loss:0.013217 [38400/50000]\n",
      "loss:0.011805 [40960/50000]\n",
      "loss:0.059595 [43520/50000]\n",
      "loss:0.056154 [46080/50000]\n",
      "loss:0.025958 [48640/50000]\n",
      "test: acc 77.08000183105469\n"
     ]
    }
   ],
   "source": [
    "for t in range(epoch):\n",
    "    print(f\"epoch {t+1} \\n----------------------------------------------\")\n",
    "    train(trainLoader,model,loss,optimizer)\n",
    "    acc=test(testLoader,model,loss,max_correct)\n",
    "    writer.add_scalar(\"acc_ResNet vs epoch\",acc,t)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalar(\"acc_ResNet vs epoch\",0,0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
