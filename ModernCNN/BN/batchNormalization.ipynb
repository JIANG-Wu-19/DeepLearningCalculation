{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:23:39.112839100Z",
     "start_time": "2024-03-04T09:23:35.376085700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def batch_norm(X,gamma,beta,moving_mean,moving_var,eps,momentum):\n",
    "    if not torch.is_grad_enabled():\n",
    "        X_hat=(X-moving_mean)/torch.sqrt(moving_var+eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2,4)\n",
    "\n",
    "        if len(X.shape)==2:\n",
    "            mean=X.mean(dim=0)\n",
    "            var=((X-mean)**2).mean(dim=0)\n",
    "        else:\n",
    "            mean=X.mean(dim=(0,2,3),keepdim=True)\n",
    "            var=((X-mean)**2).mean(dim=(0,2,3),keepdim=True)\n",
    "\n",
    "        X_hat=(X-mean)/torch.sqrt(var+eps)\n",
    "\n",
    "        moving_mean=momentum*moving_mean+(1.0-momentum)*mean\n",
    "        moving_var=momentum*moving_var+(1.0-momentum)*var\n",
    "    Y=gamma*X_hat+beta\n",
    "    return Y,moving_mean.data,moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self,num_features,num_dims):\n",
    "        super(BatchNorm,self).__init__()\n",
    "        if num_dims==2:\n",
    "            shape=(1,num_features)\n",
    "        else:\n",
    "            shape=(1,num_features,1,1)\n",
    "        self.gamma=nn.Parameter(torch.ones(shape))\n",
    "        self.beta=nn.Parameter(torch.zeros(shape))\n",
    "        self.moving_mean=torch.zeros(shape)\n",
    "        self.moving_var=torch.zeros(shape)\n",
    "\n",
    "    def forward(self,X):\n",
    "        if self.moving_mean.device!=X.device:\n",
    "            self.moving_mean=self.moving_mean.to(X.device)\n",
    "            self.moving_var=self.moving_var.to(X.device)\n",
    "        Y,self.moving_mean,self.moving_var=batch_norm(X,self.gamma,self.beta,self.moving_mean,self.moving_var,eps=1e-5,momentum=0.9)\n",
    "        return Y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:23:58.265369200Z",
     "start_time": "2024-03-04T09:23:58.252404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "net=nn.Sequential(\n",
    "    nn.Conv2d(1,6,5),\n",
    "    BatchNorm(6,num_dims=4),\n",
    "    nn.Sigmoid(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Conv2d(6,16,5),\n",
    "    BatchNorm(16,num_dims=4),\n",
    "    nn.Sigmoid(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16*4*4,120),\n",
    "    BatchNorm(120,num_dims=2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120,84),\n",
    "    BatchNorm(84,num_dims=2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84,10)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:24:48.850671600Z",
     "start_time": "2024-03-04T09:24:48.845628900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Resize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:25:06.591573Z",
     "start_time": "2024-03-04T09:25:06.067889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \n",
      "---------------------\n",
      "loss:2.544879 [    0/ 60000]\n",
      "loss:0.944075 [ 2560/ 60000]\n",
      "loss:0.318252 [ 5120/ 60000]\n",
      "loss:0.241130 [ 7680/ 60000]\n",
      "loss:0.177844 [10240/ 60000]\n",
      "loss:0.145672 [12800/ 60000]\n",
      "loss:0.143897 [15360/ 60000]\n",
      "loss:0.188408 [17920/ 60000]\n",
      "loss:0.176945 [20480/ 60000]\n",
      "loss:0.165357 [23040/ 60000]\n",
      "loss:0.075873 [25600/ 60000]\n",
      "loss:0.113786 [28160/ 60000]\n",
      "loss:0.155481 [30720/ 60000]\n",
      "loss:0.057228 [33280/ 60000]\n",
      "loss:0.098955 [35840/ 60000]\n",
      "loss:0.146092 [38400/ 60000]\n",
      "loss:0.136419 [40960/ 60000]\n",
      "loss:0.064658 [43520/ 60000]\n",
      "loss:0.154321 [46080/ 60000]\n",
      "loss:0.069446 [48640/ 60000]\n",
      "loss:0.058521 [51200/ 60000]\n",
      "loss:0.077671 [53760/ 60000]\n",
      "loss:0.064381 [56320/ 60000]\n",
      "loss:0.084365 [58880/ 60000]\n",
      "test: acc 97.20999908447266\n",
      "epoch 1 \n",
      "---------------------\n",
      "loss:0.046129 [    0/ 60000]\n",
      "loss:0.064040 [ 2560/ 60000]\n",
      "loss:0.052796 [ 5120/ 60000]\n",
      "loss:0.077006 [ 7680/ 60000]\n",
      "loss:0.096489 [10240/ 60000]\n",
      "loss:0.121403 [12800/ 60000]\n",
      "loss:0.043085 [15360/ 60000]\n",
      "loss:0.099646 [17920/ 60000]\n",
      "loss:0.048148 [20480/ 60000]\n",
      "loss:0.055043 [23040/ 60000]\n",
      "loss:0.043335 [25600/ 60000]\n",
      "loss:0.073849 [28160/ 60000]\n",
      "loss:0.026404 [30720/ 60000]\n",
      "loss:0.040704 [33280/ 60000]\n",
      "loss:0.063998 [35840/ 60000]\n",
      "loss:0.063391 [38400/ 60000]\n",
      "loss:0.064215 [40960/ 60000]\n",
      "loss:0.041966 [43520/ 60000]\n",
      "loss:0.037425 [46080/ 60000]\n",
      "loss:0.062838 [48640/ 60000]\n",
      "loss:0.038594 [51200/ 60000]\n",
      "loss:0.044944 [53760/ 60000]\n",
      "loss:0.023917 [56320/ 60000]\n",
      "loss:0.065315 [58880/ 60000]\n",
      "test: acc 97.94999694824219\n",
      "epoch 2 \n",
      "---------------------\n",
      "loss:0.020065 [    0/ 60000]\n",
      "loss:0.046107 [ 2560/ 60000]\n",
      "loss:0.070285 [ 5120/ 60000]\n",
      "loss:0.017836 [ 7680/ 60000]\n",
      "loss:0.023691 [10240/ 60000]\n",
      "loss:0.078065 [12800/ 60000]\n",
      "loss:0.051341 [15360/ 60000]\n",
      "loss:0.028855 [17920/ 60000]\n",
      "loss:0.062282 [20480/ 60000]\n",
      "loss:0.026475 [23040/ 60000]\n",
      "loss:0.031097 [25600/ 60000]\n",
      "loss:0.028534 [28160/ 60000]\n",
      "loss:0.040718 [30720/ 60000]\n",
      "loss:0.046546 [33280/ 60000]\n",
      "loss:0.033458 [35840/ 60000]\n",
      "loss:0.013470 [38400/ 60000]\n",
      "loss:0.025982 [40960/ 60000]\n",
      "loss:0.014437 [43520/ 60000]\n",
      "loss:0.013452 [46080/ 60000]\n",
      "loss:0.031118 [48640/ 60000]\n",
      "loss:0.057835 [51200/ 60000]\n",
      "loss:0.063423 [53760/ 60000]\n",
      "loss:0.025038 [56320/ 60000]\n",
      "loss:0.023010 [58880/ 60000]\n",
      "test: acc 98.52999877929688\n",
      "epoch 3 \n",
      "---------------------\n",
      "loss:0.052302 [    0/ 60000]\n",
      "loss:0.034904 [ 2560/ 60000]\n",
      "loss:0.045660 [ 5120/ 60000]\n",
      "loss:0.031850 [ 7680/ 60000]\n",
      "loss:0.016473 [10240/ 60000]\n",
      "loss:0.033537 [12800/ 60000]\n",
      "loss:0.047137 [15360/ 60000]\n",
      "loss:0.014417 [17920/ 60000]\n",
      "loss:0.034670 [20480/ 60000]\n",
      "loss:0.029127 [23040/ 60000]\n",
      "loss:0.033875 [25600/ 60000]\n",
      "loss:0.014179 [28160/ 60000]\n",
      "loss:0.033778 [30720/ 60000]\n",
      "loss:0.035096 [33280/ 60000]\n",
      "loss:0.017697 [35840/ 60000]\n",
      "loss:0.082544 [38400/ 60000]\n",
      "loss:0.008483 [40960/ 60000]\n",
      "loss:0.019559 [43520/ 60000]\n",
      "loss:0.067122 [46080/ 60000]\n",
      "loss:0.038575 [48640/ 60000]\n",
      "loss:0.022785 [51200/ 60000]\n",
      "loss:0.088802 [53760/ 60000]\n",
      "loss:0.040512 [56320/ 60000]\n",
      "loss:0.021585 [58880/ 60000]\n",
      "test: acc 98.43999481201172\n",
      "epoch 4 \n",
      "---------------------\n",
      "loss:0.061836 [    0/ 60000]\n",
      "loss:0.056143 [ 2560/ 60000]\n",
      "loss:0.050954 [ 5120/ 60000]\n",
      "loss:0.010644 [ 7680/ 60000]\n",
      "loss:0.070153 [10240/ 60000]\n",
      "loss:0.047521 [12800/ 60000]\n",
      "loss:0.017904 [15360/ 60000]\n",
      "loss:0.046142 [17920/ 60000]\n",
      "loss:0.030277 [20480/ 60000]\n",
      "loss:0.010337 [23040/ 60000]\n",
      "loss:0.046191 [25600/ 60000]\n",
      "loss:0.038118 [28160/ 60000]\n",
      "loss:0.023275 [30720/ 60000]\n",
      "loss:0.027885 [33280/ 60000]\n",
      "loss:0.039180 [35840/ 60000]\n",
      "loss:0.015256 [38400/ 60000]\n",
      "loss:0.011028 [40960/ 60000]\n",
      "loss:0.040590 [43520/ 60000]\n",
      "loss:0.053900 [46080/ 60000]\n",
      "loss:0.013275 [48640/ 60000]\n",
      "loss:0.025784 [51200/ 60000]\n",
      "loss:0.018705 [53760/ 60000]\n",
      "loss:0.041309 [56320/ 60000]\n",
      "loss:0.024814 [58880/ 60000]\n",
      "test: acc 98.00999450683594\n",
      "epoch 5 \n",
      "---------------------\n",
      "loss:0.024917 [    0/ 60000]\n",
      "loss:0.042467 [ 2560/ 60000]\n",
      "loss:0.010263 [ 5120/ 60000]\n",
      "loss:0.030988 [ 7680/ 60000]\n",
      "loss:0.013101 [10240/ 60000]\n",
      "loss:0.029146 [12800/ 60000]\n",
      "loss:0.021024 [15360/ 60000]\n",
      "loss:0.005627 [17920/ 60000]\n",
      "loss:0.039804 [20480/ 60000]\n",
      "loss:0.047459 [23040/ 60000]\n",
      "loss:0.022292 [25600/ 60000]\n",
      "loss:0.040813 [28160/ 60000]\n",
      "loss:0.026137 [30720/ 60000]\n",
      "loss:0.011752 [33280/ 60000]\n",
      "loss:0.047731 [35840/ 60000]\n",
      "loss:0.013947 [38400/ 60000]\n",
      "loss:0.033290 [40960/ 60000]\n",
      "loss:0.037456 [43520/ 60000]\n",
      "loss:0.011841 [46080/ 60000]\n",
      "loss:0.024736 [48640/ 60000]\n",
      "loss:0.111339 [51200/ 60000]\n",
      "loss:0.030866 [53760/ 60000]\n",
      "loss:0.044840 [56320/ 60000]\n",
      "loss:0.030452 [58880/ 60000]\n",
      "test: acc 98.72000122070312\n",
      "epoch 6 \n",
      "---------------------\n",
      "loss:0.012186 [    0/ 60000]\n",
      "loss:0.009763 [ 2560/ 60000]\n",
      "loss:0.017756 [ 5120/ 60000]\n",
      "loss:0.016577 [ 7680/ 60000]\n",
      "loss:0.015573 [10240/ 60000]\n",
      "loss:0.024421 [12800/ 60000]\n",
      "loss:0.023846 [15360/ 60000]\n",
      "loss:0.026004 [17920/ 60000]\n",
      "loss:0.014035 [20480/ 60000]\n",
      "loss:0.040599 [23040/ 60000]\n",
      "loss:0.034800 [25600/ 60000]\n",
      "loss:0.008401 [28160/ 60000]\n",
      "loss:0.012131 [30720/ 60000]\n",
      "loss:0.004586 [33280/ 60000]\n",
      "loss:0.009437 [35840/ 60000]\n",
      "loss:0.021770 [38400/ 60000]\n",
      "loss:0.030334 [40960/ 60000]\n",
      "loss:0.016765 [43520/ 60000]\n",
      "loss:0.020323 [46080/ 60000]\n",
      "loss:0.020351 [48640/ 60000]\n",
      "loss:0.012271 [51200/ 60000]\n",
      "loss:0.029592 [53760/ 60000]\n",
      "loss:0.033590 [56320/ 60000]\n",
      "loss:0.029515 [58880/ 60000]\n",
      "test: acc 98.91999816894531\n",
      "epoch 7 \n",
      "---------------------\n",
      "loss:0.035715 [    0/ 60000]\n",
      "loss:0.006215 [ 2560/ 60000]\n",
      "loss:0.017897 [ 5120/ 60000]\n",
      "loss:0.040946 [ 7680/ 60000]\n",
      "loss:0.028207 [10240/ 60000]\n",
      "loss:0.026196 [12800/ 60000]\n",
      "loss:0.014962 [15360/ 60000]\n",
      "loss:0.003781 [17920/ 60000]\n",
      "loss:0.004060 [20480/ 60000]\n",
      "loss:0.024657 [23040/ 60000]\n",
      "loss:0.002431 [25600/ 60000]\n",
      "loss:0.013509 [28160/ 60000]\n",
      "loss:0.014354 [30720/ 60000]\n",
      "loss:0.014008 [33280/ 60000]\n",
      "loss:0.012742 [35840/ 60000]\n",
      "loss:0.008332 [38400/ 60000]\n",
      "loss:0.024536 [40960/ 60000]\n",
      "loss:0.020583 [43520/ 60000]\n",
      "loss:0.047443 [46080/ 60000]\n",
      "loss:0.027735 [48640/ 60000]\n",
      "loss:0.013366 [51200/ 60000]\n",
      "loss:0.059193 [53760/ 60000]\n",
      "loss:0.016642 [56320/ 60000]\n",
      "loss:0.010237 [58880/ 60000]\n",
      "test: acc 98.54999542236328\n",
      "epoch 8 \n",
      "---------------------\n",
      "loss:0.006878 [    0/ 60000]\n",
      "loss:0.004642 [ 2560/ 60000]\n",
      "loss:0.016485 [ 5120/ 60000]\n",
      "loss:0.015647 [ 7680/ 60000]\n",
      "loss:0.005153 [10240/ 60000]\n",
      "loss:0.023169 [12800/ 60000]\n",
      "loss:0.028990 [15360/ 60000]\n",
      "loss:0.033900 [17920/ 60000]\n",
      "loss:0.007861 [20480/ 60000]\n",
      "loss:0.008115 [23040/ 60000]\n",
      "loss:0.074592 [25600/ 60000]\n",
      "loss:0.014280 [28160/ 60000]\n",
      "loss:0.004903 [30720/ 60000]\n",
      "loss:0.032715 [33280/ 60000]\n",
      "loss:0.022029 [35840/ 60000]\n",
      "loss:0.027484 [38400/ 60000]\n",
      "loss:0.022957 [40960/ 60000]\n",
      "loss:0.104131 [43520/ 60000]\n",
      "loss:0.041369 [46080/ 60000]\n",
      "loss:0.051125 [48640/ 60000]\n",
      "loss:0.019636 [51200/ 60000]\n",
      "loss:0.021214 [53760/ 60000]\n",
      "loss:0.009182 [56320/ 60000]\n",
      "loss:0.001266 [58880/ 60000]\n",
      "test: acc 99.07999420166016\n",
      "epoch 9 \n",
      "---------------------\n",
      "loss:0.031296 [    0/ 60000]\n",
      "loss:0.006569 [ 2560/ 60000]\n",
      "loss:0.044493 [ 5120/ 60000]\n",
      "loss:0.003241 [ 7680/ 60000]\n",
      "loss:0.036023 [10240/ 60000]\n",
      "loss:0.003488 [12800/ 60000]\n",
      "loss:0.028193 [15360/ 60000]\n",
      "loss:0.088740 [17920/ 60000]\n",
      "loss:0.003925 [20480/ 60000]\n",
      "loss:0.018431 [23040/ 60000]\n",
      "loss:0.042313 [25600/ 60000]\n",
      "loss:0.048878 [28160/ 60000]\n",
      "loss:0.004480 [30720/ 60000]\n",
      "loss:0.003717 [33280/ 60000]\n",
      "loss:0.009209 [35840/ 60000]\n",
      "loss:0.028587 [38400/ 60000]\n",
      "loss:0.013962 [40960/ 60000]\n",
      "loss:0.028808 [43520/ 60000]\n",
      "loss:0.019198 [46080/ 60000]\n",
      "loss:0.006325 [48640/ 60000]\n",
      "loss:0.008031 [51200/ 60000]\n",
      "loss:0.007971 [53760/ 60000]\n",
      "loss:0.017682 [56320/ 60000]\n",
      "loss:0.019007 [58880/ 60000]\n",
      "test: acc 98.75999450683594\n",
      "epoch 10 \n",
      "---------------------\n",
      "loss:0.002557 [    0/ 60000]\n",
      "loss:0.004450 [ 2560/ 60000]\n",
      "loss:0.008670 [ 5120/ 60000]\n",
      "loss:0.025215 [ 7680/ 60000]\n",
      "loss:0.018194 [10240/ 60000]\n",
      "loss:0.015075 [12800/ 60000]\n",
      "loss:0.002572 [15360/ 60000]\n",
      "loss:0.030857 [17920/ 60000]\n",
      "loss:0.004164 [20480/ 60000]\n",
      "loss:0.009906 [23040/ 60000]\n",
      "loss:0.008299 [25600/ 60000]\n",
      "loss:0.037236 [28160/ 60000]\n",
      "loss:0.025600 [30720/ 60000]\n",
      "loss:0.005513 [33280/ 60000]\n",
      "loss:0.010897 [35840/ 60000]\n",
      "loss:0.032356 [38400/ 60000]\n",
      "loss:0.002429 [40960/ 60000]\n",
      "loss:0.010178 [43520/ 60000]\n",
      "loss:0.042398 [46080/ 60000]\n",
      "loss:0.001377 [48640/ 60000]\n",
      "loss:0.010567 [51200/ 60000]\n",
      "loss:0.047927 [53760/ 60000]\n",
      "loss:0.030708 [56320/ 60000]\n",
      "loss:0.040583 [58880/ 60000]\n",
      "test: acc 98.81999969482422\n",
      "epoch 11 \n",
      "---------------------\n",
      "loss:0.002643 [    0/ 60000]\n",
      "loss:0.025379 [ 2560/ 60000]\n",
      "loss:0.009505 [ 5120/ 60000]\n",
      "loss:0.016867 [ 7680/ 60000]\n",
      "loss:0.019816 [10240/ 60000]\n",
      "loss:0.009566 [12800/ 60000]\n",
      "loss:0.019474 [15360/ 60000]\n",
      "loss:0.005858 [17920/ 60000]\n",
      "loss:0.024839 [20480/ 60000]\n",
      "loss:0.023040 [23040/ 60000]\n",
      "loss:0.002242 [25600/ 60000]\n",
      "loss:0.004829 [28160/ 60000]\n",
      "loss:0.013731 [30720/ 60000]\n",
      "loss:0.003500 [33280/ 60000]\n",
      "loss:0.013977 [35840/ 60000]\n",
      "loss:0.008216 [38400/ 60000]\n",
      "loss:0.002586 [40960/ 60000]\n",
      "loss:0.019606 [43520/ 60000]\n",
      "loss:0.038611 [46080/ 60000]\n",
      "loss:0.006441 [48640/ 60000]\n",
      "loss:0.016621 [51200/ 60000]\n",
      "loss:0.015788 [53760/ 60000]\n",
      "loss:0.007830 [56320/ 60000]\n",
      "loss:0.016323 [58880/ 60000]\n",
      "test: acc 98.86000061035156\n",
      "epoch 12 \n",
      "---------------------\n",
      "loss:0.014613 [    0/ 60000]\n",
      "loss:0.003891 [ 2560/ 60000]\n",
      "loss:0.003474 [ 5120/ 60000]\n",
      "loss:0.009072 [ 7680/ 60000]\n",
      "loss:0.006030 [10240/ 60000]\n",
      "loss:0.003480 [12800/ 60000]\n",
      "loss:0.001446 [15360/ 60000]\n",
      "loss:0.004749 [17920/ 60000]\n",
      "loss:0.000371 [20480/ 60000]\n",
      "loss:0.002184 [23040/ 60000]\n",
      "loss:0.006223 [25600/ 60000]\n",
      "loss:0.006441 [28160/ 60000]\n",
      "loss:0.007387 [30720/ 60000]\n",
      "loss:0.009561 [33280/ 60000]\n",
      "loss:0.014512 [35840/ 60000]\n",
      "loss:0.004392 [38400/ 60000]\n",
      "loss:0.002762 [40960/ 60000]\n",
      "loss:0.004882 [43520/ 60000]\n",
      "loss:0.005106 [46080/ 60000]\n",
      "loss:0.003711 [48640/ 60000]\n",
      "loss:0.013095 [51200/ 60000]\n",
      "loss:0.005240 [53760/ 60000]\n",
      "loss:0.007297 [56320/ 60000]\n",
      "loss:0.015987 [58880/ 60000]\n",
      "test: acc 98.90999603271484\n",
      "epoch 13 \n",
      "---------------------\n",
      "loss:0.005252 [    0/ 60000]\n",
      "loss:0.003208 [ 2560/ 60000]\n",
      "loss:0.014230 [ 5120/ 60000]\n",
      "loss:0.012863 [ 7680/ 60000]\n",
      "loss:0.014450 [10240/ 60000]\n",
      "loss:0.001578 [12800/ 60000]\n",
      "loss:0.017915 [15360/ 60000]\n",
      "loss:0.020512 [17920/ 60000]\n",
      "loss:0.005288 [20480/ 60000]\n",
      "loss:0.004765 [23040/ 60000]\n",
      "loss:0.010938 [25600/ 60000]\n",
      "loss:0.024295 [28160/ 60000]\n",
      "loss:0.003449 [30720/ 60000]\n",
      "loss:0.000718 [33280/ 60000]\n",
      "loss:0.013725 [35840/ 60000]\n",
      "loss:0.003653 [38400/ 60000]\n",
      "loss:0.005766 [40960/ 60000]\n",
      "loss:0.002914 [43520/ 60000]\n",
      "loss:0.003487 [46080/ 60000]\n",
      "loss:0.006465 [48640/ 60000]\n",
      "loss:0.008176 [51200/ 60000]\n",
      "loss:0.001985 [53760/ 60000]\n",
      "loss:0.008253 [56320/ 60000]\n",
      "loss:0.005006 [58880/ 60000]\n",
      "test: acc 99.13999938964844\n",
      "epoch 14 \n",
      "---------------------\n",
      "loss:0.001953 [    0/ 60000]\n",
      "loss:0.005409 [ 2560/ 60000]\n",
      "loss:0.004473 [ 5120/ 60000]\n",
      "loss:0.007931 [ 7680/ 60000]\n",
      "loss:0.002190 [10240/ 60000]\n",
      "loss:0.018139 [12800/ 60000]\n",
      "loss:0.003554 [15360/ 60000]\n",
      "loss:0.006014 [17920/ 60000]\n",
      "loss:0.000749 [20480/ 60000]\n",
      "loss:0.003284 [23040/ 60000]\n",
      "loss:0.004129 [25600/ 60000]\n",
      "loss:0.002116 [28160/ 60000]\n",
      "loss:0.005499 [30720/ 60000]\n",
      "loss:0.007445 [33280/ 60000]\n",
      "loss:0.004414 [35840/ 60000]\n",
      "loss:0.009134 [38400/ 60000]\n",
      "loss:0.015206 [40960/ 60000]\n",
      "loss:0.003843 [43520/ 60000]\n",
      "loss:0.003640 [46080/ 60000]\n",
      "loss:0.002100 [48640/ 60000]\n",
      "loss:0.001618 [51200/ 60000]\n",
      "loss:0.072735 [53760/ 60000]\n",
      "loss:0.002466 [56320/ 60000]\n",
      "loss:0.000472 [58880/ 60000]\n",
      "test: acc 98.93999481201172\n",
      "epoch 15 \n",
      "---------------------\n",
      "loss:0.014013 [    0/ 60000]\n",
      "loss:0.001991 [ 2560/ 60000]\n",
      "loss:0.012035 [ 5120/ 60000]\n",
      "loss:0.004446 [ 7680/ 60000]\n",
      "loss:0.006124 [10240/ 60000]\n",
      "loss:0.000755 [12800/ 60000]\n",
      "loss:0.006380 [15360/ 60000]\n",
      "loss:0.053596 [17920/ 60000]\n",
      "loss:0.001461 [20480/ 60000]\n",
      "loss:0.006515 [23040/ 60000]\n",
      "loss:0.013404 [25600/ 60000]\n",
      "loss:0.011546 [28160/ 60000]\n",
      "loss:0.018353 [30720/ 60000]\n",
      "loss:0.003814 [33280/ 60000]\n",
      "loss:0.014949 [35840/ 60000]\n",
      "loss:0.002078 [38400/ 60000]\n",
      "loss:0.006394 [40960/ 60000]\n",
      "loss:0.029496 [43520/ 60000]\n",
      "loss:0.005806 [46080/ 60000]\n",
      "loss:0.001303 [48640/ 60000]\n",
      "loss:0.010111 [51200/ 60000]\n",
      "loss:0.009694 [53760/ 60000]\n",
      "loss:0.021405 [56320/ 60000]\n",
      "loss:0.007993 [58880/ 60000]\n",
      "test: acc 98.97000122070312\n",
      "epoch 16 \n",
      "---------------------\n",
      "loss:0.002997 [    0/ 60000]\n",
      "loss:0.007738 [ 2560/ 60000]\n",
      "loss:0.002127 [ 5120/ 60000]\n",
      "loss:0.007125 [ 7680/ 60000]\n",
      "loss:0.007878 [10240/ 60000]\n",
      "loss:0.001124 [12800/ 60000]\n",
      "loss:0.017814 [15360/ 60000]\n",
      "loss:0.001453 [17920/ 60000]\n",
      "loss:0.004213 [20480/ 60000]\n",
      "loss:0.000592 [23040/ 60000]\n",
      "loss:0.014590 [25600/ 60000]\n",
      "loss:0.004920 [28160/ 60000]\n",
      "loss:0.007694 [30720/ 60000]\n",
      "loss:0.004521 [33280/ 60000]\n",
      "loss:0.014132 [35840/ 60000]\n",
      "loss:0.010522 [38400/ 60000]\n",
      "loss:0.007871 [40960/ 60000]\n",
      "loss:0.003431 [43520/ 60000]\n",
      "loss:0.015798 [46080/ 60000]\n",
      "loss:0.002547 [48640/ 60000]\n",
      "loss:0.010891 [51200/ 60000]\n",
      "loss:0.010461 [53760/ 60000]\n",
      "loss:0.002606 [56320/ 60000]\n",
      "loss:0.019575 [58880/ 60000]\n",
      "test: acc 98.93000030517578\n",
      "epoch 17 \n",
      "---------------------\n",
      "loss:0.002126 [    0/ 60000]\n",
      "loss:0.015451 [ 2560/ 60000]\n",
      "loss:0.015220 [ 5120/ 60000]\n",
      "loss:0.002554 [ 7680/ 60000]\n",
      "loss:0.000879 [10240/ 60000]\n",
      "loss:0.008214 [12800/ 60000]\n",
      "loss:0.021090 [15360/ 60000]\n",
      "loss:0.020027 [17920/ 60000]\n",
      "loss:0.016389 [20480/ 60000]\n",
      "loss:0.002123 [23040/ 60000]\n",
      "loss:0.017937 [25600/ 60000]\n",
      "loss:0.024099 [28160/ 60000]\n",
      "loss:0.000879 [30720/ 60000]\n",
      "loss:0.002889 [33280/ 60000]\n",
      "loss:0.002300 [35840/ 60000]\n",
      "loss:0.008762 [38400/ 60000]\n",
      "loss:0.005926 [40960/ 60000]\n",
      "loss:0.002261 [43520/ 60000]\n",
      "loss:0.057503 [46080/ 60000]\n",
      "loss:0.016310 [48640/ 60000]\n",
      "loss:0.002881 [51200/ 60000]\n",
      "loss:0.008756 [53760/ 60000]\n",
      "loss:0.003718 [56320/ 60000]\n",
      "loss:0.002824 [58880/ 60000]\n",
      "test: acc 98.87999725341797\n",
      "epoch 18 \n",
      "---------------------\n",
      "loss:0.001762 [    0/ 60000]\n",
      "loss:0.002307 [ 2560/ 60000]\n",
      "loss:0.006766 [ 5120/ 60000]\n",
      "loss:0.003805 [ 7680/ 60000]\n",
      "loss:0.001153 [10240/ 60000]\n",
      "loss:0.004880 [12800/ 60000]\n",
      "loss:0.009315 [15360/ 60000]\n",
      "loss:0.001020 [17920/ 60000]\n",
      "loss:0.006005 [20480/ 60000]\n",
      "loss:0.000949 [23040/ 60000]\n",
      "loss:0.000780 [25600/ 60000]\n",
      "loss:0.006908 [28160/ 60000]\n",
      "loss:0.001065 [30720/ 60000]\n",
      "loss:0.002455 [33280/ 60000]\n",
      "loss:0.002218 [35840/ 60000]\n",
      "loss:0.023482 [38400/ 60000]\n",
      "loss:0.000178 [40960/ 60000]\n",
      "loss:0.000876 [43520/ 60000]\n",
      "loss:0.003114 [46080/ 60000]\n",
      "loss:0.000805 [48640/ 60000]\n",
      "loss:0.007187 [51200/ 60000]\n",
      "loss:0.011977 [53760/ 60000]\n",
      "loss:0.000754 [56320/ 60000]\n",
      "loss:0.000952 [58880/ 60000]\n",
      "test: acc 99.00999450683594\n",
      "epoch 19 \n",
      "---------------------\n",
      "loss:0.002757 [    0/ 60000]\n",
      "loss:0.006351 [ 2560/ 60000]\n",
      "loss:0.008591 [ 5120/ 60000]\n",
      "loss:0.000204 [ 7680/ 60000]\n",
      "loss:0.001678 [10240/ 60000]\n",
      "loss:0.008770 [12800/ 60000]\n",
      "loss:0.007412 [15360/ 60000]\n",
      "loss:0.000847 [17920/ 60000]\n",
      "loss:0.000590 [20480/ 60000]\n",
      "loss:0.001492 [23040/ 60000]\n",
      "loss:0.002943 [25600/ 60000]\n",
      "loss:0.001153 [28160/ 60000]\n",
      "loss:0.009969 [30720/ 60000]\n",
      "loss:0.002438 [33280/ 60000]\n",
      "loss:0.013514 [35840/ 60000]\n",
      "loss:0.000734 [38400/ 60000]\n",
      "loss:0.011206 [40960/ 60000]\n",
      "loss:0.007035 [43520/ 60000]\n",
      "loss:0.000958 [46080/ 60000]\n",
      "loss:0.002172 [48640/ 60000]\n",
      "loss:0.015340 [51200/ 60000]\n",
      "loss:0.004180 [53760/ 60000]\n",
      "loss:0.001394 [56320/ 60000]\n",
      "loss:0.017293 [58880/ 60000]\n",
      "test: acc 98.69999694824219\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "mnist_training = datasets.MNIST(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "mnist_test = datasets.MNIST(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "lr = 1\n",
    "epochs = 20\n",
    "\n",
    "train_dataloader = DataLoader(mnist_training, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# net = xxxNet().to(device)\n",
    "net=net.to(device)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "net.apply(init_weights)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\n",
    "        f\"epoch {epoch} \\n---------------------\"\n",
    "    )\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(inputs)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d}/ 60000]\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        for (image, label) in test_dataloader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            output = net(image)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            acc += (pred == label).sum()\n",
    "\n",
    "        print(f\"test: acc {100 * acc / total}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:29:34.611198900Z",
     "start_time": "2024-03-04T09:26:25.349040400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([3.9467, 2.6483, 2.2780, 1.6499, 2.1272, 3.9457], device='cuda:0',\n        grad_fn=<ReshapeAliasBackward0>),\n tensor([-3.3139,  0.1249,  1.6347, -1.7970, -0.5650, -2.7569], device='cuda:0',\n        grad_fn=<ReshapeAliasBackward0>))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1].gamma.reshape((-1,)), net[1].beta.reshape((-1,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:29:52.252845600Z",
     "start_time": "2024-03-04T09:29:52.232897Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \n",
      "---------------------\n",
      "loss:2.610928 [    0/ 60000]\n",
      "loss:0.774725 [ 2560/ 60000]\n",
      "loss:0.248046 [ 5120/ 60000]\n",
      "loss:0.226470 [ 7680/ 60000]\n",
      "loss:0.281178 [10240/ 60000]\n",
      "loss:0.134376 [12800/ 60000]\n",
      "loss:0.177315 [15360/ 60000]\n",
      "loss:0.128242 [17920/ 60000]\n",
      "loss:0.103134 [20480/ 60000]\n",
      "loss:0.120544 [23040/ 60000]\n",
      "loss:0.104558 [25600/ 60000]\n",
      "loss:0.129680 [28160/ 60000]\n",
      "loss:0.120950 [30720/ 60000]\n",
      "loss:0.126245 [33280/ 60000]\n",
      "loss:0.091974 [35840/ 60000]\n",
      "loss:0.062910 [38400/ 60000]\n",
      "loss:0.127991 [40960/ 60000]\n",
      "loss:0.111706 [43520/ 60000]\n",
      "loss:0.085169 [46080/ 60000]\n",
      "loss:0.061671 [48640/ 60000]\n",
      "loss:0.078981 [51200/ 60000]\n",
      "loss:0.091333 [53760/ 60000]\n",
      "loss:0.061117 [56320/ 60000]\n",
      "loss:0.115154 [58880/ 60000]\n",
      "test: acc 98.0199966430664\n",
      "epoch 1 \n",
      "---------------------\n",
      "loss:0.081720 [    0/ 60000]\n",
      "loss:0.100422 [ 2560/ 60000]\n",
      "loss:0.109519 [ 5120/ 60000]\n",
      "loss:0.085373 [ 7680/ 60000]\n",
      "loss:0.043798 [10240/ 60000]\n",
      "loss:0.061911 [12800/ 60000]\n",
      "loss:0.110254 [15360/ 60000]\n",
      "loss:0.033089 [17920/ 60000]\n",
      "loss:0.031757 [20480/ 60000]\n",
      "loss:0.080177 [23040/ 60000]\n",
      "loss:0.034423 [25600/ 60000]\n",
      "loss:0.085574 [28160/ 60000]\n",
      "loss:0.070681 [30720/ 60000]\n",
      "loss:0.060425 [33280/ 60000]\n",
      "loss:0.113612 [35840/ 60000]\n",
      "loss:0.091405 [38400/ 60000]\n",
      "loss:0.028680 [40960/ 60000]\n",
      "loss:0.077242 [43520/ 60000]\n",
      "loss:0.042360 [46080/ 60000]\n",
      "loss:0.064835 [48640/ 60000]\n",
      "loss:0.018739 [51200/ 60000]\n",
      "loss:0.096955 [53760/ 60000]\n",
      "loss:0.053368 [56320/ 60000]\n",
      "loss:0.057974 [58880/ 60000]\n",
      "test: acc 98.38999938964844\n",
      "epoch 2 \n",
      "---------------------\n",
      "loss:0.057577 [    0/ 60000]\n",
      "loss:0.030964 [ 2560/ 60000]\n",
      "loss:0.078600 [ 5120/ 60000]\n",
      "loss:0.040988 [ 7680/ 60000]\n",
      "loss:0.044353 [10240/ 60000]\n",
      "loss:0.032977 [12800/ 60000]\n",
      "loss:0.032897 [15360/ 60000]\n",
      "loss:0.034456 [17920/ 60000]\n",
      "loss:0.078522 [20480/ 60000]\n",
      "loss:0.071869 [23040/ 60000]\n",
      "loss:0.062116 [25600/ 60000]\n",
      "loss:0.036128 [28160/ 60000]\n",
      "loss:0.038895 [30720/ 60000]\n",
      "loss:0.042436 [33280/ 60000]\n",
      "loss:0.117829 [35840/ 60000]\n",
      "loss:0.053726 [38400/ 60000]\n",
      "loss:0.027644 [40960/ 60000]\n",
      "loss:0.165168 [43520/ 60000]\n",
      "loss:0.059574 [46080/ 60000]\n",
      "loss:0.053714 [48640/ 60000]\n",
      "loss:0.029186 [51200/ 60000]\n",
      "loss:0.049456 [53760/ 60000]\n",
      "loss:0.094409 [56320/ 60000]\n",
      "loss:0.062955 [58880/ 60000]\n",
      "test: acc 98.63999938964844\n",
      "epoch 3 \n",
      "---------------------\n",
      "loss:0.018634 [    0/ 60000]\n",
      "loss:0.051341 [ 2560/ 60000]\n",
      "loss:0.040809 [ 5120/ 60000]\n",
      "loss:0.074520 [ 7680/ 60000]\n",
      "loss:0.032697 [10240/ 60000]\n",
      "loss:0.039237 [12800/ 60000]\n",
      "loss:0.073555 [15360/ 60000]\n",
      "loss:0.022853 [17920/ 60000]\n",
      "loss:0.120173 [20480/ 60000]\n",
      "loss:0.042633 [23040/ 60000]\n",
      "loss:0.053973 [25600/ 60000]\n",
      "loss:0.012328 [28160/ 60000]\n",
      "loss:0.023772 [30720/ 60000]\n",
      "loss:0.022839 [33280/ 60000]\n",
      "loss:0.045074 [35840/ 60000]\n",
      "loss:0.032562 [38400/ 60000]\n",
      "loss:0.037766 [40960/ 60000]\n",
      "loss:0.067437 [43520/ 60000]\n",
      "loss:0.038149 [46080/ 60000]\n",
      "loss:0.019643 [48640/ 60000]\n",
      "loss:0.023411 [51200/ 60000]\n",
      "loss:0.031867 [53760/ 60000]\n",
      "loss:0.025362 [56320/ 60000]\n",
      "loss:0.032808 [58880/ 60000]\n",
      "test: acc 98.6199951171875\n",
      "epoch 4 \n",
      "---------------------\n",
      "loss:0.011767 [    0/ 60000]\n",
      "loss:0.019359 [ 2560/ 60000]\n",
      "loss:0.033683 [ 5120/ 60000]\n",
      "loss:0.014331 [ 7680/ 60000]\n",
      "loss:0.005467 [10240/ 60000]\n",
      "loss:0.008638 [12800/ 60000]\n",
      "loss:0.010605 [15360/ 60000]\n",
      "loss:0.077943 [17920/ 60000]\n",
      "loss:0.034867 [20480/ 60000]\n",
      "loss:0.060607 [23040/ 60000]\n",
      "loss:0.078493 [25600/ 60000]\n",
      "loss:0.050758 [28160/ 60000]\n",
      "loss:0.038912 [30720/ 60000]\n",
      "loss:0.017667 [33280/ 60000]\n",
      "loss:0.058199 [35840/ 60000]\n",
      "loss:0.024351 [38400/ 60000]\n",
      "loss:0.020921 [40960/ 60000]\n",
      "loss:0.011605 [43520/ 60000]\n",
      "loss:0.040981 [46080/ 60000]\n",
      "loss:0.008156 [48640/ 60000]\n",
      "loss:0.024919 [51200/ 60000]\n",
      "loss:0.078931 [53760/ 60000]\n",
      "loss:0.017123 [56320/ 60000]\n",
      "loss:0.043354 [58880/ 60000]\n",
      "test: acc 98.66999816894531\n",
      "epoch 5 \n",
      "---------------------\n",
      "loss:0.039389 [    0/ 60000]\n",
      "loss:0.041342 [ 2560/ 60000]\n",
      "loss:0.018714 [ 5120/ 60000]\n",
      "loss:0.034530 [ 7680/ 60000]\n",
      "loss:0.015299 [10240/ 60000]\n",
      "loss:0.015824 [12800/ 60000]\n",
      "loss:0.041149 [15360/ 60000]\n",
      "loss:0.007039 [17920/ 60000]\n",
      "loss:0.013096 [20480/ 60000]\n",
      "loss:0.028934 [23040/ 60000]\n",
      "loss:0.007204 [25600/ 60000]\n",
      "loss:0.026938 [28160/ 60000]\n",
      "loss:0.015709 [30720/ 60000]\n",
      "loss:0.061934 [33280/ 60000]\n",
      "loss:0.050156 [35840/ 60000]\n",
      "loss:0.036852 [38400/ 60000]\n",
      "loss:0.012991 [40960/ 60000]\n",
      "loss:0.024403 [43520/ 60000]\n",
      "loss:0.034163 [46080/ 60000]\n",
      "loss:0.036879 [48640/ 60000]\n",
      "loss:0.040230 [51200/ 60000]\n",
      "loss:0.052878 [53760/ 60000]\n",
      "loss:0.010062 [56320/ 60000]\n",
      "loss:0.035900 [58880/ 60000]\n",
      "test: acc 98.79000091552734\n",
      "epoch 6 \n",
      "---------------------\n",
      "loss:0.026586 [    0/ 60000]\n",
      "loss:0.003093 [ 2560/ 60000]\n",
      "loss:0.002945 [ 5120/ 60000]\n",
      "loss:0.014737 [ 7680/ 60000]\n",
      "loss:0.021844 [10240/ 60000]\n",
      "loss:0.014372 [12800/ 60000]\n",
      "loss:0.046625 [15360/ 60000]\n",
      "loss:0.015528 [17920/ 60000]\n",
      "loss:0.005563 [20480/ 60000]\n",
      "loss:0.028201 [23040/ 60000]\n",
      "loss:0.005382 [25600/ 60000]\n",
      "loss:0.042571 [28160/ 60000]\n",
      "loss:0.052203 [30720/ 60000]\n",
      "loss:0.016876 [33280/ 60000]\n",
      "loss:0.021703 [35840/ 60000]\n",
      "loss:0.015884 [38400/ 60000]\n",
      "loss:0.020838 [40960/ 60000]\n",
      "loss:0.043628 [43520/ 60000]\n",
      "loss:0.015366 [46080/ 60000]\n",
      "loss:0.013526 [48640/ 60000]\n",
      "loss:0.034293 [51200/ 60000]\n",
      "loss:0.019995 [53760/ 60000]\n",
      "loss:0.018002 [56320/ 60000]\n",
      "loss:0.008631 [58880/ 60000]\n",
      "test: acc 98.88999938964844\n",
      "epoch 7 \n",
      "---------------------\n",
      "loss:0.006955 [    0/ 60000]\n",
      "loss:0.008913 [ 2560/ 60000]\n",
      "loss:0.039588 [ 5120/ 60000]\n",
      "loss:0.010668 [ 7680/ 60000]\n",
      "loss:0.017569 [10240/ 60000]\n",
      "loss:0.041225 [12800/ 60000]\n",
      "loss:0.002247 [15360/ 60000]\n",
      "loss:0.026641 [17920/ 60000]\n",
      "loss:0.003538 [20480/ 60000]\n",
      "loss:0.056609 [23040/ 60000]\n",
      "loss:0.014237 [25600/ 60000]\n",
      "loss:0.034203 [28160/ 60000]\n",
      "loss:0.003406 [30720/ 60000]\n",
      "loss:0.020036 [33280/ 60000]\n",
      "loss:0.055150 [35840/ 60000]\n",
      "loss:0.012381 [38400/ 60000]\n",
      "loss:0.021619 [40960/ 60000]\n",
      "loss:0.020328 [43520/ 60000]\n",
      "loss:0.007246 [46080/ 60000]\n",
      "loss:0.041571 [48640/ 60000]\n",
      "loss:0.002156 [51200/ 60000]\n",
      "loss:0.067566 [53760/ 60000]\n",
      "loss:0.018589 [56320/ 60000]\n",
      "loss:0.058722 [58880/ 60000]\n",
      "test: acc 98.63999938964844\n",
      "epoch 8 \n",
      "---------------------\n",
      "loss:0.007221 [    0/ 60000]\n",
      "loss:0.017160 [ 2560/ 60000]\n",
      "loss:0.016099 [ 5120/ 60000]\n",
      "loss:0.015928 [ 7680/ 60000]\n",
      "loss:0.008074 [10240/ 60000]\n",
      "loss:0.004029 [12800/ 60000]\n",
      "loss:0.002024 [15360/ 60000]\n",
      "loss:0.008563 [17920/ 60000]\n",
      "loss:0.010386 [20480/ 60000]\n",
      "loss:0.006432 [23040/ 60000]\n",
      "loss:0.009219 [25600/ 60000]\n",
      "loss:0.002763 [28160/ 60000]\n",
      "loss:0.029542 [30720/ 60000]\n",
      "loss:0.014200 [33280/ 60000]\n",
      "loss:0.042022 [35840/ 60000]\n",
      "loss:0.006674 [38400/ 60000]\n",
      "loss:0.012068 [40960/ 60000]\n",
      "loss:0.023823 [43520/ 60000]\n",
      "loss:0.028562 [46080/ 60000]\n",
      "loss:0.014521 [48640/ 60000]\n",
      "loss:0.017040 [51200/ 60000]\n",
      "loss:0.005732 [53760/ 60000]\n",
      "loss:0.016337 [56320/ 60000]\n",
      "loss:0.022570 [58880/ 60000]\n",
      "test: acc 98.93000030517578\n",
      "epoch 9 \n",
      "---------------------\n",
      "loss:0.007941 [    0/ 60000]\n",
      "loss:0.011270 [ 2560/ 60000]\n",
      "loss:0.020399 [ 5120/ 60000]\n",
      "loss:0.026350 [ 7680/ 60000]\n",
      "loss:0.006279 [10240/ 60000]\n",
      "loss:0.009540 [12800/ 60000]\n",
      "loss:0.015079 [15360/ 60000]\n",
      "loss:0.005341 [17920/ 60000]\n",
      "loss:0.011669 [20480/ 60000]\n",
      "loss:0.006576 [23040/ 60000]\n",
      "loss:0.005063 [25600/ 60000]\n",
      "loss:0.005556 [28160/ 60000]\n",
      "loss:0.019508 [30720/ 60000]\n",
      "loss:0.008632 [33280/ 60000]\n",
      "loss:0.005833 [35840/ 60000]\n",
      "loss:0.001985 [38400/ 60000]\n",
      "loss:0.009074 [40960/ 60000]\n",
      "loss:0.001378 [43520/ 60000]\n",
      "loss:0.025351 [46080/ 60000]\n",
      "loss:0.007143 [48640/ 60000]\n",
      "loss:0.011206 [51200/ 60000]\n",
      "loss:0.019006 [53760/ 60000]\n",
      "loss:0.007638 [56320/ 60000]\n",
      "loss:0.034648 [58880/ 60000]\n",
      "test: acc 98.7699966430664\n",
      "epoch 10 \n",
      "---------------------\n",
      "loss:0.034102 [    0/ 60000]\n",
      "loss:0.016205 [ 2560/ 60000]\n",
      "loss:0.028697 [ 5120/ 60000]\n",
      "loss:0.012065 [ 7680/ 60000]\n",
      "loss:0.025206 [10240/ 60000]\n",
      "loss:0.019596 [12800/ 60000]\n",
      "loss:0.034602 [15360/ 60000]\n",
      "loss:0.024643 [17920/ 60000]\n",
      "loss:0.008440 [20480/ 60000]\n",
      "loss:0.030560 [23040/ 60000]\n",
      "loss:0.003688 [25600/ 60000]\n",
      "loss:0.015091 [28160/ 60000]\n",
      "loss:0.007210 [30720/ 60000]\n",
      "loss:0.009180 [33280/ 60000]\n",
      "loss:0.008643 [35840/ 60000]\n",
      "loss:0.021818 [38400/ 60000]\n",
      "loss:0.012135 [40960/ 60000]\n",
      "loss:0.008537 [43520/ 60000]\n",
      "loss:0.003707 [46080/ 60000]\n",
      "loss:0.032146 [48640/ 60000]\n",
      "loss:0.010333 [51200/ 60000]\n",
      "loss:0.002711 [53760/ 60000]\n",
      "loss:0.019687 [56320/ 60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 34\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m     31\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m---------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     32\u001B[0m     )\n\u001B[1;32m---> 34\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch, (inputs, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[0;32m     35\u001B[0m         inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     37\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mE:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mE:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    676\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 677\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    679\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mE:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mE:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mE:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001B[0m, in \u001B[0;36mMNIST.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    142\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img\u001B[38;5;241m.\u001B[39mnumpy(), mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 145\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(img)\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    148\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[1;32mE:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m t(img)\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32mE:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[0;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mto_tensor(pic)\n",
      "File \u001B[1;32mE:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torchvision\\transforms\\functional.py:170\u001B[0m, in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pic\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    169\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;241m*\u001B[39m img\n\u001B[1;32m--> 170\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mview(pic\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m1\u001B[39m], pic\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m0\u001B[39m], F_pil\u001B[38;5;241m.\u001B[39mget_image_num_channels(pic))\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# put it from HWC to CHW format\u001B[39;00m\n\u001B[0;32m    172\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mcontiguous()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "net=nn.Sequential(\n",
    "    nn.Conv2d(1,6,5),\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.Sigmoid(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Conv2d(6,16,5),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.Sigmoid(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16*4*4,120),\n",
    "    nn.BatchNorm1d(120),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120,84),\n",
    "    nn.BatchNorm1d(84),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84,10)\n",
    ").to(device)\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "net.apply(init_weights)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\n",
    "        f\"epoch {epoch} \\n---------------------\"\n",
    "    )\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(inputs)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d}/ 60000]\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        for (image, label) in test_dataloader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            output = net(image)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            acc += (pred == label).sum()\n",
    "\n",
    "        print(f\"test: acc {100 * acc / total}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:31:27.920392200Z",
     "start_time": "2024-03-04T10:29:55.419829800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
